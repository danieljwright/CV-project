{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-09T09:26:32.654239Z","iopub.status.busy":"2024-06-09T09:26:32.653829Z","iopub.status.idle":"2024-06-09T09:26:33.535157Z","shell.execute_reply":"2024-06-09T09:26:33.534121Z","shell.execute_reply.started":"2024-06-09T09:26:32.654202Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:33.545286Z","iopub.status.busy":"2024-06-09T09:26:33.544949Z","iopub.status.idle":"2024-06-09T09:26:42.422038Z","shell.execute_reply":"2024-06-09T09:26:42.420798Z","shell.execute_reply.started":"2024-06-09T09:26:33.545253Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import copy\n","from tqdm import tqdm\n","\n","\n","# Define a transform to normalize the data\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # Convert images to tensors\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize the pixel values to range [-1, 1]\n","])\n","\n","# Download the training data\n","trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n","# Download the testset\n","testset = datasets.MNIST('~/.pytorch/MNIST_data', train=False,\n","                                       download=True, transform=transform)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.424148Z","iopub.status.busy":"2024-06-09T09:26:42.423419Z","iopub.status.idle":"2024-06-09T09:26:42.435406Z","shell.execute_reply":"2024-06-09T09:26:42.434395Z","shell.execute_reply.started":"2024-06-09T09:26:42.424105Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["60000\n"]}],"source":["indices = list(range(len(trainset)))\n","np.random.shuffle(indices)\n","shuffled_trainset = torch.utils.data.Subset(trainset, indices)\n","print(len(shuffled_trainset))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.437422Z","iopub.status.busy":"2024-06-09T09:26:42.436416Z","iopub.status.idle":"2024-06-09T09:26:42.448866Z","shell.execute_reply":"2024-06-09T09:26:42.447959Z","shell.execute_reply.started":"2024-06-09T09:26:42.437395Z"},"trusted":true},"outputs":[],"source":["'''dataset1 = []\n","dataset2 = []\n","dataset3 = []\n","dataset4 = []\n","dataset5 = []\n","dataset6 = []\n","\n","for i in range(10000):\n","    dataset1 = torch.utils.data.Subset(full_dataset, list(range(10000)))\n","    dataset1.append(shuffled_trainset[i])\n","    \n","for i in range(10000, 20000):\n","    \n","    dataset2.append(shuffled_trainset[i])\n","    \n","for i in range(20000, 30000):\n","    \n","    dataset3.append(shuffled_trainset[i])\n","    \n","for i in range(30000, 40000):\n","    \n","    dataset4.append(shuffled_trainset[i])\n","    \n","for i in range(40000, 50000):\n","    \n","    dataset5.append(shuffled_trainset[i])\n","for i in range(50000, 60000):\n","    \n","    dataset6.append(shuffled_trainset[i])'''\n","    \n","dataset1 = torch.utils.data.Subset(shuffled_trainset, list(range(10000)))\n","dataset2 = torch.utils.data.Subset(shuffled_trainset, list(range(10000, 20000)))\n","dataset3 = torch.utils.data.Subset(shuffled_trainset, list(range(20000, 30000)))\n","dataset4 = torch.utils.data.Subset(shuffled_trainset, list(range(30000, 40000)))\n","dataset5 = torch.utils.data.Subset(shuffled_trainset, list(range(40000, 50000)))\n","dataset6 = torch.utils.data.Subset(shuffled_trainset, list(range(50000, 60000)))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.450291Z","iopub.status.busy":"2024-06-09T09:26:42.450007Z","iopub.status.idle":"2024-06-09T09:26:42.461114Z","shell.execute_reply":"2024-06-09T09:26:42.460268Z","shell.execute_reply.started":"2024-06-09T09:26:42.450266Z"},"trusted":true},"outputs":[],"source":["batch_size=64\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False)\n","trainloader = torch.utils.data.DataLoader(shuffled_trainset, batch_size=batch_size,\n","                                         shuffle=False)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.462805Z","iopub.status.busy":"2024-06-09T09:26:42.462417Z","iopub.status.idle":"2024-06-09T09:26:42.470759Z","shell.execute_reply":"2024-06-09T09:26:42.469873Z","shell.execute_reply.started":"2024-06-09T09:26:42.462768Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(npimg)\n","    plt.show()\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.472722Z","iopub.status.busy":"2024-06-09T09:26:42.472032Z","iopub.status.idle":"2024-06-09T09:26:42.513841Z","shell.execute_reply":"2024-06-09T09:26:42.512893Z","shell.execute_reply.started":"2024-06-09T09:26:42.472686Z"},"trusted":true},"outputs":[],"source":["from torchvision.transforms import v2\n","\n","def apply_perspective_transform(image):\n","\n","\n","    mean = torch.mean(image)\n","    std = torch.std(image)\n","\n","    perspective_transform = v2.Compose([\n","        v2.RandomPerspective(distortion_scale=0.3, p=1.0, fill=-1),\n","        v2.ToDtype(torch.float32, scale=True),\n","        #v2.Normalize(mean=[mean], std=[std]),\n","    ])\n","\n","    transformed_image = perspective_transform(image)\n","    transformed_image = transformed_image.reshape(28,28)\n","\n","    return transformed_image"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.519266Z","iopub.status.busy":"2024-06-09T09:26:42.518961Z","iopub.status.idle":"2024-06-09T09:26:42.904421Z","shell.execute_reply":"2024-06-09T09:26:42.903402Z","shell.execute_reply.started":"2024-06-09T09:26:42.519241Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["out = apply_perspective_transform(dataset1[0][0])\n","imshow(out)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:42.905788Z","iopub.status.busy":"2024-06-09T09:26:42.905507Z","iopub.status.idle":"2024-06-09T09:26:43.127753Z","shell.execute_reply":"2024-06-09T09:26:43.126498Z","shell.execute_reply.started":"2024-06-09T09:26:42.905763Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def apply_blur(image):\n","\n","\n","    blurrer = v2.GaussianBlur(kernel_size=5, sigma=(1, 2.))\n","\n","    transformed_image = blurrer(image)\n","    transformed_image = transformed_image.reshape(28,28)\n","\n","    return transformed_image\n","\n","\n","out = apply_blur(dataset1[0][0])\n","\n","\n","imshow(out)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:43.129277Z","iopub.status.busy":"2024-06-09T09:26:43.128967Z","iopub.status.idle":"2024-06-09T09:26:43.368979Z","shell.execute_reply":"2024-06-09T09:26:43.368053Z","shell.execute_reply.started":"2024-06-09T09:26:43.129250Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def apply_gaussian_noise(image):\n","\n","    noise = np.random.normal(scale=0.5,size=(28,28))\n","\n","    transformed_image = image + noise\n","    transformed_image = transformed_image.reshape(28,28)\n","\n","    return transformed_image\n","\n","out = apply_gaussian_noise(dataset1[0][0])\n","\n","\n","imshow(out)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:43.370676Z","iopub.status.busy":"2024-06-09T09:26:43.370313Z","iopub.status.idle":"2024-06-09T09:26:43.606832Z","shell.execute_reply":"2024-06-09T09:26:43.605922Z","shell.execute_reply.started":"2024-06-09T09:26:43.370642Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def apply_random_erase(image):\n","\n","\n","    erase = v2.RandomErasing(value=-1)\n","\n","    transformed_image = erase(image)\n","    transformed_image = transformed_image.reshape(28,28)\n","\n","    return transformed_image\n","\n","out = apply_random_erase(dataset1[0][0])\n","\n","\n","imshow(out)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:43.608458Z","iopub.status.busy":"2024-06-09T09:26:43.608087Z","iopub.status.idle":"2024-06-09T09:26:43.848065Z","shell.execute_reply":"2024-06-09T09:26:43.847181Z","shell.execute_reply.started":"2024-06-09T09:26:43.608424Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def apply_elastic_transform(image):\n","    elastic_transformer = v2.ElasticTransform(alpha=50.0)\n","    transformed_image = elastic_transformer(image)\n","    transformed_image = transformed_image.reshape(28, 28)\n","    return transformed_image\n","\n","out = apply_elastic_transform(dataset1[0][0])\n","imshow(out)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:43.849768Z","iopub.status.busy":"2024-06-09T09:26:43.849378Z","iopub.status.idle":"2024-06-09T09:26:44.087833Z","shell.execute_reply":"2024-06-09T09:26:44.086944Z","shell.execute_reply.started":"2024-06-09T09:26:43.849730Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def apply_random_rotation(image):\n","    rotater = v2.RandomRotation(degrees=(0, 30))\n","    transformed_image = rotater(image)\n","    transformed_image = transformed_image.reshape(28, 28)\n","    return transformed_image\n","\n","out = apply_random_rotation(dataset1[0][0])\n","imshow(out)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:26:44.089460Z","iopub.status.busy":"2024-06-09T09:26:44.089070Z","iopub.status.idle":"2024-06-09T09:27:53.046867Z","shell.execute_reply":"2024-06-09T09:27:53.045838Z","shell.execute_reply.started":"2024-06-09T09:26:44.089410Z"},"trusted":true},"outputs":[],"source":["'''print(len(dataset1))\n","train_1 = []\n","for i in range(10000):\n","    train_1.append([apply_perspective_transform(dataset1[i][0]), dataset1[i][1]])\n","print(len(train_1))\n","train_2 = []\n","for i in range(10000):\n","    train_2.append(apply_blur(dataset2[i][0]))\n","train_3 = []\n","for i in range(10000):\n","    train_3.append(apply_gaussian_noise(dataset3[i][0]))\n","train_4 = []\n","for i in range(10000):\n","    train_4.append(apply_random_erase(dataset4[i][0]))\n","train_5 = []\n","for i in range(10000):\n","    train_5.append(apply_elastic_transform(dataset5[i][0]))\n","train_6 = []\n","for i in range(10000):\n","    train_6.append(apply_random_rotation(dataset6[i][0]))'''\n","\n","for i in range(10000):\n","    dataset1[i][0] == apply_perspective_transform(dataset1[i][0])\n","for i in range(10000):\n","    dataset2[i][0] == apply_blur(dataset2[i][0])\n","for i in range(10000):\n","    dataset3[i][0] == apply_gaussian_noise(dataset3[i][0])\n","for i in range(10000):\n","    dataset4[i][0] == apply_random_erase(dataset4[i][0])\n","for i in range(10000):\n","    dataset5[i][0] == apply_elastic_transform(dataset5[i][0])\n","for i in range(10000):\n","    dataset6[i][0] == apply_random_rotation(dataset6[i][0])"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:27:53.049707Z","iopub.status.busy":"2024-06-09T09:27:53.049263Z","iopub.status.idle":"2024-06-09T09:27:53.058774Z","shell.execute_reply":"2024-06-09T09:27:53.057643Z","shell.execute_reply.started":"2024-06-09T09:27:53.049670Z"},"trusted":true},"outputs":[],"source":["batch_size=64\n","trainloaders = []\n","train_loader_1 = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=False)\n","train_loader_2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle=False)\n","train_loader_3 = torch.utils.data.DataLoader(dataset3, batch_size=batch_size, shuffle=False)\n","train_loader_4 = torch.utils.data.DataLoader(dataset4, batch_size=batch_size, shuffle=False)\n","train_loader_5 = torch.utils.data.DataLoader(dataset5, batch_size=batch_size, shuffle=False)\n","train_loader_6 = torch.utils.data.DataLoader(dataset6, batch_size=batch_size, shuffle=False)\n","trainloaders.append(trainloader)\n","trainloaders.append(train_loader_1)\n","trainloaders.append(train_loader_2)\n","trainloaders.append(train_loader_3)\n","trainloaders.append(train_loader_4)\n","trainloaders.append(train_loader_5)\n","trainloaders.append(train_loader_6)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:27:53.060592Z","iopub.status.busy":"2024-06-09T09:27:53.060272Z","iopub.status.idle":"2024-06-09T09:27:53.077255Z","shell.execute_reply":"2024-06-09T09:27:53.076368Z","shell.execute_reply.started":"2024-06-09T09:27:53.060562Z"},"trusted":true},"outputs":[],"source":["class CustomCNN(nn.Module):\n","    def __init__(self):\n","        super(CustomCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1)\n","        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(4 * 7 * 7, 16)\n","        self.fc2 = nn.Linear(16, 10)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.max_pool(self.relu(self.conv1(x)))\n","        x = self.max_pool(self.relu(self.conv2(x)))\n","        x = x.view(-1, 4 * 7 * 7)\n","        x = self.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","    \n","\n","def generate_models():\n","\n","    models = []\n","    rand_model = CustomCNN()\n","    model1 = CustomCNN()\n","    model2 = CustomCNN()\n","    model3 = CustomCNN()\n","    model4 = CustomCNN()\n","    model5 = CustomCNN()\n","    model6 = CustomCNN()\n","\n","    \n","    models.append(model1)\n","    models.append(model2)\n","    models.append(model3)\n","    models.append(model4)\n","    models.append(model5)\n","    models.append(model6)\n","\n","    initial_rand_parms = copy.deepcopy(rand_model.state_dict())\n","\n","    return rand_model, models, initial_rand_parms"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["#initial_rand_parms = copy.deepcopy(model.state_dict())\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:27:53.078514Z","iopub.status.busy":"2024-06-09T09:27:53.078253Z","iopub.status.idle":"2024-06-09T09:27:53.087865Z","shell.execute_reply":"2024-06-09T09:27:53.087178Z","shell.execute_reply.started":"2024-06-09T09:27:53.078492Z"},"trusted":true},"outputs":[],"source":["def gen_optimizers(rand_model, models):\n","    \n","        optimizers = []\n","        rand_optimizer = optim.Adam(rand_model.parameters(), lr=0.001)\n","        optimizer1 = optim.Adam(models[0].parameters(), lr=0.001)\n","        optimizer2 = optim.Adam(models[1].parameters(), lr=0.001)\n","        optimizer3 = optim.Adam(models[2].parameters(), lr=0.001)\n","        optimizer4 = optim.Adam(models[3].parameters(), lr=0.001)\n","        optimizer5 = optim.Adam(models[4].parameters(), lr=0.001)\n","        optimizer6 = optim.Adam(models[5].parameters(), lr=0.001)\n","\n","        optimizers.append(optimizer1)\n","        optimizers.append(optimizer2)\n","        optimizers.append(optimizer3)\n","        optimizers.append(optimizer4)\n","        optimizers.append(optimizer5)\n","        optimizers.append(optimizer6)\n","    \n","        return rand_optimizer, optimizers\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","# optimizers = []\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n","# optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n","# optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n","# optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n","# optimizer4 = optim.Adam(model4.parameters(), lr=0.001)\n","# optimizer5 = optim.Adam(model5.parameters(), lr=0.001)\n","# optimizer6 = optim.Adam(model6.parameters(), lr=0.001)\n","# optimizers.append(optimizer)\n","# optimizers.append(optimizer1)\n","# optimizers.append(optimizer2)\n","# optimizers.append(optimizer3)\n","# optimizers.append(optimizer4)\n","# optimizers.append(optimizer5)\n","# optimizers.append(optimizer6)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:27:53.089579Z","iopub.status.busy":"2024-06-09T09:27:53.089061Z","iopub.status.idle":"2024-06-09T09:28:26.418284Z","shell.execute_reply":"2024-06-09T09:28:26.417351Z","shell.execute_reply.started":"2024-06-09T09:27:53.089544Z"},"trusted":true},"outputs":[],"source":["def train_rand_model(rand_model, rand_optimizer):\n","\n","    num_epochs = 2\n","    \n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            \n","            rand_optimizer.zero_grad()\n","            \n","            outputs = rand_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            rand_optimizer.step()\n","            \n","            running_loss += loss.item()\n","            if i % 100 == 99:  # print every 200 mini-batches\n","                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 200:.4f}')\n","                running_loss = 0.0\n","    \n","    #print('Finished Training')\n","\n","\n","\n","\n","def train_models(models, optimizers):\n","\n","    num_epochs = 6\n","    \n","    criterion = nn.CrossEntropyLoss()\n","    for j in tqdm(range(6)):\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            for i, data in enumerate(trainloaders[j], 0):\n","                #print(len(data))\n","                inputs, labels = data\n","                \n","                optimizers[j].zero_grad()\n","                \n","                outputs = models[j](inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizers[j].step()\n","                \n","                running_loss += loss.item()\n","                if i % 100 == 99:  # print every 200 mini-batches\n","                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloaders[j])}], Loss: {running_loss / 200:.4f}')\n","                    running_loss = 0.0\n","        \n","    #print('Finished Training')"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:28:26.420363Z","iopub.status.busy":"2024-06-09T09:28:26.419624Z","iopub.status.idle":"2024-06-09T09:28:28.750717Z","shell.execute_reply":"2024-06-09T09:28:28.749863Z","shell.execute_reply.started":"2024-06-09T09:28:26.420331Z"},"trusted":true},"outputs":[],"source":["def test_model(model):\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    #print(f'Accuracy of th randomly initialized network on the 10000 test images: {100 * correct / total:.2f}%')\n","    return 100 * correct / total\n","\n","\n","# correct = 0\n","# total = 0\n","\n","# with torch.no_grad():\n","#     for data in testloader:\n","#         images, labels = data\n","#         outputs = model(images)\n","#         _, predicted = torch.max(outputs.data, 1)\n","#         total += labels.size(0)\n","#         correct += (predicted == labels).sum().item()\n","\n","# print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:28:28.752069Z","iopub.status.busy":"2024-06-09T09:28:28.751790Z","iopub.status.idle":"2024-06-09T09:28:28.765638Z","shell.execute_reply":"2024-06-09T09:28:28.764620Z","shell.execute_reply.started":"2024-06-09T09:28:28.752043Z"},"trusted":true},"outputs":[],"source":["# state_dict = model.state_dict()\n","# for param_tensor in state_dict:\n","#     print(f\"{param_tensor}:\\n {state_dict[param_tensor].numpy()}\\n\")\n","    \n","# filters = state_dict[\"conv2.weight\"]\n","# extracted = []\n","# for i in range(filters.shape[0]):\n","#     for j in range(filters.shape[1]):\n","        "]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:28:28.767724Z","iopub.status.busy":"2024-06-09T09:28:28.766949Z","iopub.status.idle":"2024-06-09T09:28:28.774449Z","shell.execute_reply":"2024-06-09T09:28:28.773463Z","shell.execute_reply.started":"2024-06-09T09:28:28.767684Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"# PAIRWISE SIMILARITY\\nfrom sklearn.metrics.pairwise import pairwise_distances\\nfrom torch.nn import functional as F\\n\\nX = extracted[0]\\nY = extracted[1]\\n\\nsim = pairwise_distances(X, Y, metric='cosine')\\nprint(sim)\\n\\n\\nXf = extracted[0].view(-1)\\nYf = extracted[1].view(-1)\\n\\nsimF = F.cosine_similarity(Xf, Yf, dim=0)\\nprint(simF)\""]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["'''from torch.nn import functional as F\n","\n","# calculate similarity along the rows\n","print(extracted[0])\n","tensor1 = extracted[0].unsqueeze(1)\n","tensor2 = extracted[1].unsqueeze(1)\n","cosine_similarity_row = F.cosine_similarity(tensor1, tensor2, dim=2)\n","print(cosine_similarity_row)'''\n","\n","'''# PAIRWISE SIMILARITY\n","from sklearn.metrics.pairwise import pairwise_distances\n","from torch.nn import functional as F\n","\n","X = extracted[0]\n","Y = extracted[1]\n","\n","sim = pairwise_distances(X, Y, metric='cosine')\n","print(sim)\n","\n","\n","Xf = extracted[0].view(-1)\n","Yf = extracted[1].view(-1)\n","\n","simF = F.cosine_similarity(Xf, Yf, dim=0)\n","print(simF)'''\n","\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:36:39.272519Z","iopub.status.busy":"2024-06-09T09:36:39.271777Z","iopub.status.idle":"2024-06-09T09:36:39.277993Z","shell.execute_reply":"2024-06-09T09:36:39.276932Z","shell.execute_reply.started":"2024-06-09T09:36:39.272482Z"},"trusted":true},"outputs":[],"source":["def calc_overall_sim(tensor1, tensor2):\n","    \n","    tensor1_flat = tensor1.view(-1)\n","    tensor2_flat = tensor2.view(-1)\n","    \n","    similarity = F.cosine_similarity(tensor1_flat, tensor2_flat, dim=0)\n","    similarity = torch.abs(similarity)\n","    \n","    return similarity.detach().numpy().reshape(1,)[0]"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:36:41.152700Z","iopub.status.busy":"2024-06-09T09:36:41.151817Z","iopub.status.idle":"2024-06-09T09:36:41.157518Z","shell.execute_reply":"2024-06-09T09:36:41.156477Z","shell.execute_reply.started":"2024-06-09T09:36:41.152664Z"},"trusted":true},"outputs":[],"source":["def calc_pearson_coeff(tensor1, tensor2):\n","    corr_coeff = np.corrcoef(tensor1.detach().numpy().flatten(), tensor2.detach().numpy().flatten())[0,1]\n","    corr_coeff = np.abs(corr_coeff)\n","    return corr_coeff"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:36:41.618615Z","iopub.status.busy":"2024-06-09T09:36:41.618228Z","iopub.status.idle":"2024-06-09T09:36:41.624416Z","shell.execute_reply":"2024-06-09T09:36:41.623365Z","shell.execute_reply.started":"2024-06-09T09:36:41.618582Z"},"trusted":true},"outputs":[],"source":["def calc_frob_norm(tensor1, tensor2):\n","    A = tensor1.detach().numpy()\n","    B = tensor2.detach().numpy()\n","    frobenius_norm = np.linalg.norm(A - B, ord='fro')\n","    return frobenius_norm"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:36:42.228054Z","iopub.status.busy":"2024-06-09T09:36:42.227017Z","iopub.status.idle":"2024-06-09T09:36:42.270644Z","shell.execute_reply":"2024-06-09T09:36:42.269747Z","shell.execute_reply.started":"2024-06-09T09:36:42.228020Z"},"trusted":true},"outputs":[],"source":["from torch.nn import functional as F\n","import matplotlib.pyplot as plt\n","#similarity_scores = np.zeros((6,8))\n","def compare_filters(models, metrics=['overall_sim', 'pearson_coeff', 'frob_norm']):\n","\n","    similarity_scores_1 = []\n","    similarity_scores_2 = []\n","    similarity_scores_3 = []\n","    similarity_scores_4 = []\n","    similarity_scores_5 = []\n","    similarity_scores_6 = []\n","    similarity_scores_7 = []\n","    similarity_scores_8 = []\n","    similarity_scores_9 = []\n","    similarity_scores_10 = []\n","\n","    for i in range(1, 6):\n","\n","        cnn_filters_i = models[i].conv1.weight\n","        cnn_filters_i = cnn_filters_i.view(cnn_filters_i.size(0)*cnn_filters_i.size(1), cnn_filters_i.size(2), cnn_filters_i.size(3))   \n","        for j in range(2):\n","\n","            filter1 = cnn_filters_i[j]\n","\n","            for k in range(i+1, 6):\n","                cnn_filters_k = models[k].conv1.weight\n","                cnn_filters_k = cnn_filters_k.view(cnn_filters_k.size(0)*cnn_filters_k.size(1), cnn_filters_k.size(2), cnn_filters_k.size(3))\n","                filter2 = cnn_filters_k[j]\n","                if metrics == 'overall_sim':\n","                    similarity = calc_overall_sim(filter1, filter2)\n","                elif metrics == 'pearson_coeff': \n","                    similarity = calc_pearson_coeff(filter1, filter2)\n","                elif metrics == 'frob_norm':\n","                    similarity = calc_frob_norm(filter1, filter2)\n","                #similarity = calc_overall_sim(filter1, filter2)\n","                #similarity = calc_pearson_coeff(filter1, filter2)\n","                #similarity = calc_frob_norm(filter1, filter2)\n","\n","                if j==0:\n","                    similarity_scores_1.append(similarity)\n","\n","                if j==1:\n","                    similarity_scores_2.append(similarity)\n","            \n","\n","\n","        cnn_filters = models[i].conv2.weight\n","        cnn_filters = cnn_filters.view(cnn_filters.size(0)*cnn_filters.size(1), cnn_filters.size(2), cnn_filters.size(3))\n","        print(cnn_filters.shape)\n","        \n","        for j in range(8):\n","            filter1 = cnn_filters[j]\n","            \n","            for k in range(i+1, 6):  # Fix: adjust the range to avoid out-of-bounds indices\n","                cnn_filters2 = models[k].conv2.weight\n","                cnn_filters2 = cnn_filters2.view(cnn_filters2.size(0)*cnn_filters2.size(1), cnn_filters2.size(2), cnn_filters2.size(3))\n","                filter2 = cnn_filters2[j]\n","                \n","                if metrics == 'overall_sim':\n","                    similarity = calc_overall_sim(filter1, filter2)\n","                elif metrics == 'pearson_coeff':\n","                    similarity = calc_pearson_coeff(filter1, filter2)\n","                elif metrics == 'frob_norm':\n","                    similarity = calc_frob_norm(filter1, filter2)\n","                #similarity = calc_overall_sim(filter1, filter2)\n","                #similarity = calc_pearson_coeff(filter1, filter2)\n","                #similarity = calc_frob_norm(filter1, filter2)\n","                \n","                if j==0:\n","                    similarity_scores_3.append(similarity)\n","                \n","                if j==1:\n","                    similarity_scores_4.append(similarity)\n","                \n","                if j==2:\n","                    similarity_scores_5.append(similarity)\n","                \n","                if j==3:\n","                    similarity_scores_6.append(similarity)\n","                \n","                if j==4:\n","                    similarity_scores_7.append(similarity)\n","                \n","                if j==5:\n","                    similarity_scores_8.append(similarity)\n","                \n","                if j==6:\n","                    similarity_scores_9.append(similarity)\n","                    \n","                if j==7:\n","                    similarity_scores_10.append(similarity)  \n","\n","\n","\n","\n","\n","\n","\n","    # print(similarity_scores_1)\n","    # print(similarity_scores_2)\n","    # print(similarity_scores_3)\n","    # print(similarity_scores_4)\n","    # print(similarity_scores_5)\n","    # print(similarity_scores_6)\n","    # print(similarity_scores_7)\n","    # print(similarity_scores_8)\n","    # print(similarity_scores_9)\n","    # print(similarity_scores_10)\n","\n","    return similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10\n","\n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T09:28:28.842889Z","iopub.status.busy":"2024-06-09T09:28:28.842588Z","iopub.status.idle":"2024-06-09T09:28:28.855010Z","shell.execute_reply":"2024-06-09T09:28:28.853990Z","shell.execute_reply.started":"2024-06-09T09:28:28.842864Z"},"trusted":true},"outputs":[],"source":["\n","\n","# filters_1 = []\n","# filters_2 = []\n","# filters_3 = []\n","# filters_4 = []\n","# filters_5 = []\n","# filters_6 = []\n","# filters_7 = []\n","# filters_8 = []\n","# filters_9 = []\n","# filters_10 = []\n","# for i in range(1,7):\n","#     cnn_filters = models[i].conv1.weight\n","#     cnn_filters = cnn_filters.view(cnn_filters.size(0)*cnn_filters.size(1), cnn_filters.size(2), cnn_filters.size(3))\n","#     for j in range(2):\n","#         if j==0:\n","#             filters_1.append(cnn_filters[j].detach().numpy())\n","#         if j==1:\n","#             filters_2.append(cnn_filters[j].detach().numpy())\n","#     cnn_filters = models[i].conv2.weight\n","#     cnn_filters = cnn_filters.view(cnn_filters.size(0)*cnn_filters.size(1), cnn_filters.size(2), cnn_filters.size(3))\n","\n","#     for j in range(8):\n","#         if j==0:\n","#             filters_3.append(cnn_filters[j].detach().numpy())\n","#         if j==1:\n","#             filters_4.append(cnn_filters[j].detach().numpy())\n","#         if j==2:\n","#             filters_5.append(cnn_filters[j].detach().numpy())\n","#         if j==3:\n","#             filters_6.append(cnn_filters[j].detach().numpy())\n","#         if j==4:\n","#             filters_7.append(cnn_filters[j].detach().numpy())\n","#         if j==5:\n","#             filters_8.append(cnn_filters[j].detach().numpy())\n","#         if j==6:\n","#             filters_9.append(cnn_filters[j].detach().numpy())  \n","#         if j==7:   \n","#             filters_10.append(cnn_filters[j].detach().numpy())\n","            \n","# matrices = np.array(filters_1)\n","# variance_matrix = np.var(matrices, axis=0)   \n","# print(variance_matrix)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["\n","\n","def get_max_index(similarity_scores):\n","    max_index = np.argmax(similarity_scores)\n","    return max_index\n","\n","def get_max_index(similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10):\n","\n","    filter1_idx = np.argmax(similarity_scores_1)\n","    filter2_idx = np.argmax(similarity_scores_2)\n","    filter3_idx = np.argmax(similarity_scores_3)\n","    filter4_idx = np.argmax(similarity_scores_4)\n","    filter5_idx = np.argmax(similarity_scores_5)\n","    filter6_idx = np.argmax(similarity_scores_6)\n","    filter7_idx = np.argmax(similarity_scores_7)\n","    filter8_idx = np.argmax(similarity_scores_8)\n","    filter9_idx = np.argmax(similarity_scores_9)\n","    filter10_idx = np.argmax(similarity_scores_10)\n","\n","    indexes = [filter1_idx, filter2_idx, filter3_idx, filter4_idx, filter5_idx, filter6_idx, filter7_idx, filter8_idx, filter9_idx, filter10_idx]\n","\n","\n","    # print(\"Filter 1 index:\", filter1_idx)\n","    # print(\"Filter 2 index:\", filter2_idx)\n","    # print(\"Filter 3 index:\", filter3_idx)\n","    # print(\"Filter 4 index:\", filter4_idx)\n","    # print(\"Filter 5 index:\", filter5_idx)\n","    # print(\"Filter 6 index:\", filter6_idx)\n","    # print(\"Filter 7 index:\", filter7_idx)\n","    # print(\"Filter 8 index:\", filter8_idx)\n","    # print(\"Filter 9 index:\", filter9_idx)\n","    # print(\"Filter 10 index:\", filter10_idx)\n","\n","    return indexes\n","\n","\n","\n","#(1,2) (1,3) (1,4) (1,5) (1,6) (2,3) (2,4) (2,5) (2,6)  (3,4) (3,5) (3,6) (4,5) (4,6) (5,6)\n","\n","\n","#with torch.no_grad():\n"," #   net.conv1.weight[1][1] = torch.zeros((3, 3))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# Hand coding in the filters\n","\n","def select_filters(models, indexes):\n","    selected_filters = []\n","\n","    for i, idx in enumerate(indexes):\n","        if idx in range(0,5):\n","            if i == 0 or i == 1:\n","                selected_filters.append(models[1].conv1.weight[i])\n","            else:\n","                selected_filters.append(models[1].conv2.weight[(i//2)-1][i%2])\n","\n","        if idx in range(5,9):\n","            if i == 0 or i == 1:\n","                selected_filters.append(models[2].conv1.weight[i])\n","            else:\n","                selected_filters.append(models[2].conv2.weight[(i//2)-1][i%2])\n","        if idx in range(9,12):\n","            if i == 0 or i == 1:\n","                selected_filters.append(models[3].conv1.weight[i])\n","            else:\n","                selected_filters.append(models[3].conv2.weight[(i//2)-1][i%2])\n","        if idx in range(12,14):\n","            if i == 0 or i == 1:\n","                selected_filters.append(models[4].conv1.weight[i])\n","            else:\n","                selected_filters.append(models[4].conv2.weight[(i//2)-1][i%2])\n","        if idx in range(14,15):\n","            if i == 0 or i == 1:\n","                selected_filters.append(models[5].conv1.weight[i])\n","            else:\n","                selected_filters.append(models[5].conv2.weight[(i//2)-1][i%2])\n","\n","    return selected_filters\n","\n","# selected_filters = []\n","\n","# for i, idx in enumerate(indexes):\n","#     if idx in range(0,5):\n","#         if i == 0 or i == 1:\n","#             selected_filters.append(model1.conv1.weight[i])\n","#         else:\n","#             selected_filters.append(model1.conv2.weight[(i//2)-1][i%2])\n","\n","#     if idx in range(5,9):\n","#         if i == 0 or i == 1:\n","#             selected_filters.append(model2.conv1.weight[i])\n","#         else:\n","#             selected_filters.append(model2.conv2.weight[(i//2)-1][i%2])\n","#     if idx in range(9,12):\n","#         if i == 0 or i == 1:\n","#             selected_filters.append(model3.conv1.weight[i])\n","#         else:\n","#             selected_filters.append(model3.conv2.weight[(i//2)-1][i%2])\n","#     if idx in range(12,14):\n","#         if i == 0 or i == 1:\n","#             selected_filters.append(model4.conv1.weight[i])\n","#         else:\n","#             selected_filters.append(model4.conv2.weight[(i//2)-1][i%2])\n","#     if idx in range(14,15):\n","#         if i == 0 or i == 1:\n","#             selected_filters.append(model5.conv1.weight[i])\n","#         else:\n","#             selected_filters.append(model5.conv2.weight[(i//2)-1][i%2])\n","    \n","        \n","        \n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# Warm starting a model with the selected filters\n","from torchsummary import summary\n","\n","\n","def gen_warm_start_model():\n","\n","    model_warm_start = CustomCNN()\n","    summary(model_warm_start, (1, 28,28))\n","\n","    with torch.no_grad():\n","        model_warm_start.conv1.weight[0] = selected_filters[0]\n","        model_warm_start.conv1.weight[1] = selected_filters[1]\n","        model_warm_start.conv2.weight[0][0] = selected_filters[2]\n","        model_warm_start.conv2.weight[0][1] = selected_filters[3]\n","        model_warm_start.conv2.weight[1][0] = selected_filters[4]\n","        model_warm_start.conv2.weight[1][1] = selected_filters[5]\n","        model_warm_start.conv2.weight[2][0] = selected_filters[6]\n","        model_warm_start.conv2.weight[2][1] = selected_filters[7]\n","        model_warm_start.conv2.weight[3][0] = selected_filters[8]\n","        model_warm_start.conv2.weight[3][1] = selected_filters[9]\n","\n","    model_warm_start.requires_grad = True\n","    torch.enable_grad\n","\n","    return model_warm_start\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["\n","\n","def train_warm_start_model(model_warm_start):\n","    num_epochs = 1\n","\n","    optimizer_warm= optim.Adam(model_warm_start.parameters(), lr=0.001)\n","\n","\n","    initial_params = copy.deepcopy(model_warm_start.state_dict())\n","    print(initial_params.keys())\n","\n","    with torch.enable_grad():\n","\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            for i, data in enumerate(trainloaders[0], 0):\n","                #print(len(data))\n","                inputs, labels = data\n","                \n","                optimizer_warm.zero_grad()\n","                \n","                outputs = model_warm_start(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer_warm.step()\n","                \n","                running_loss += loss.item()\n","                if i % 100 == 99:  # print every 200 mini-batches\n","                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloaders[0])}], Loss: {running_loss / 200:.4f}')\n","                    running_loss = 0.0\n","        \n","    # print('Finished Training')\n","\n","    print(model_warm_start.conv1.weight)\n","    final_params = model_warm_start.state_dict()\n","\n","    return initial_params, final_params\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def test_warm_start_model(model_warm_start):\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = model_warm_start(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    # print(f'Accuracy of the warm started network on the 10000 test images: {100 * correct / total:.2f}%')\n","\n","    return 100 * correct / total\n","\n","# correct = 0\n","# total = 0\n","\n","# with torch.no_grad():\n","#     for data in testloader:\n","#         images, labels = data\n","#         outputs = model_warm_start(images)\n","#         _, predicted = torch.max(outputs.data, 1)\n","#         total += labels.size(0)\n","#         correct += (predicted == labels).sum().item()\n","\n","# print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.1027\n","Epoch [1/6], Step [200/938], Loss: 0.6698\n","Epoch [1/6], Step [300/938], Loss: 0.4043\n","Epoch [1/6], Step [400/938], Loss: 0.3055\n","Epoch [1/6], Step [500/938], Loss: 0.2491\n","Epoch [1/6], Step [600/938], Loss: 0.2171\n","Epoch [1/6], Step [700/938], Loss: 0.2065\n","Epoch [1/6], Step [800/938], Loss: 0.1993\n","Epoch [1/6], Step [900/938], Loss: 0.1879\n","Epoch [2/6], Step [100/938], Loss: 0.1611\n","Epoch [2/6], Step [200/938], Loss: 0.1557\n","Epoch [2/6], Step [300/938], Loss: 0.1605\n","Epoch [2/6], Step [400/938], Loss: 0.1452\n","Epoch [2/6], Step [500/938], Loss: 0.1326\n","Epoch [2/6], Step [600/938], Loss: 0.1285\n","Epoch [2/6], Step [700/938], Loss: 0.1250\n","Epoch [2/6], Step [800/938], Loss: 0.1278\n","Epoch [2/6], Step [900/938], Loss: 0.1210\n","Epoch [3/6], Step [100/938], Loss: 0.1081\n","Epoch [3/6], Step [200/938], Loss: 0.1046\n","Epoch [3/6], Step [300/938], Loss: 0.1140\n","Epoch [3/6], Step [400/938], Loss: 0.1080\n","Epoch [3/6], Step [500/938], Loss: 0.0995\n","Epoch [3/6], Step [600/938], Loss: 0.0983\n","Epoch [3/6], Step [700/938], Loss: 0.0972\n","Epoch [3/6], Step [800/938], Loss: 0.1013\n","Epoch [3/6], Step [900/938], Loss: 0.0961\n","Epoch [4/6], Step [100/938], Loss: 0.0899\n","Epoch [4/6], Step [200/938], Loss: 0.0857\n","Epoch [4/6], Step [300/938], Loss: 0.0956\n","Epoch [4/6], Step [400/938], Loss: 0.0935\n","Epoch [4/6], Step [500/938], Loss: 0.0856\n","Epoch [4/6], Step [600/938], Loss: 0.0851\n","Epoch [4/6], Step [700/938], Loss: 0.0847\n","Epoch [4/6], Step [800/938], Loss: 0.0895\n","Epoch [4/6], Step [900/938], Loss: 0.0847\n","Epoch [5/6], Step [100/938], Loss: 0.0815\n","Epoch [5/6], Step [200/938], Loss: 0.0769\n","Epoch [5/6], Step [300/938], Loss: 0.0868\n","Epoch [5/6], Step [400/938], Loss: 0.0867\n","Epoch [5/6], Step [500/938], Loss: 0.0785\n","Epoch [5/6], Step [600/938], Loss: 0.0792\n","Epoch [5/6], Step [700/938], Loss: 0.0781\n","Epoch [5/6], Step [800/938], Loss: 0.0832\n","Epoch [5/6], Step [900/938], Loss: 0.0782\n","Epoch [6/6], Step [100/938], Loss: 0.0768\n","Epoch [6/6], Step [200/938], Loss: 0.0714\n","Epoch [6/6], Step [300/938], Loss: 0.0816\n","Epoch [6/6], Step [400/938], Loss: 0.0825\n","Epoch [6/6], Step [500/938], Loss: 0.0739\n","Epoch [6/6], Step [600/938], Loss: 0.0756\n","Epoch [6/6], Step [700/938], Loss: 0.0737\n","Epoch [6/6], Step [800/938], Loss: 0.0787\n","Epoch [6/6], Step [900/938], Loss: 0.0738\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:13<06:09, 73.89s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0647\n","Epoch [2/6], Step [100/157], Loss: 0.4103\n","Epoch [3/6], Step [100/157], Loss: 0.2614\n","Epoch [4/6], Step [100/157], Loss: 0.2089\n","Epoch [5/6], Step [100/157], Loss: 0.1783\n","Epoch [6/6], Step [100/157], Loss: 0.1567\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:26<02:30, 37.66s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9801\n","Epoch [2/6], Step [100/157], Loss: 0.3292\n","Epoch [3/6], Step [100/157], Loss: 0.2377\n","Epoch [4/6], Step [100/157], Loss: 0.2027\n","Epoch [5/6], Step [100/157], Loss: 0.1820\n","Epoch [6/6], Step [100/157], Loss: 0.1673\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:41<01:22, 27.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0996\n","Epoch [2/6], Step [100/157], Loss: 0.4114\n","Epoch [3/6], Step [100/157], Loss: 0.2648\n","Epoch [4/6], Step [100/157], Loss: 0.2185\n","Epoch [5/6], Step [100/157], Loss: 0.1914\n","Epoch [6/6], Step [100/157], Loss: 0.1728\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:56<00:45, 22.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0330\n","Epoch [2/6], Step [100/157], Loss: 0.3037\n","Epoch [3/6], Step [100/157], Loss: 0.2130\n","Epoch [4/6], Step [100/157], Loss: 0.1778\n","Epoch [5/6], Step [100/157], Loss: 0.1533\n","Epoch [6/6], Step [100/157], Loss: 0.1344\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [02:07<00:18, 18.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0516\n","Epoch [2/6], Step [100/157], Loss: 0.3259\n","Epoch [3/6], Step [100/157], Loss: 0.2061\n","Epoch [4/6], Step [100/157], Loss: 0.1681\n","Epoch [5/6], Step [100/157], Loss: 0.1443\n","Epoch [6/6], Step [100/157], Loss: 0.1267\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:15<00:00, 22.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 0.9888\n","Epoch [1/1], Step [200/938], Loss: 0.4480\n","Epoch [1/1], Step [300/938], Loss: 0.3170\n","Epoch [1/1], Step [400/938], Loss: 0.2471\n","Epoch [1/1], Step [500/938], Loss: 0.2225\n","Epoch [1/1], Step [600/938], Loss: 0.2023\n","Epoch [1/1], Step [700/938], Loss: 0.1991\n","Epoch [1/1], Step [800/938], Loss: 0.1920\n","Epoch [1/1], Step [900/938], Loss: 0.1799\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 1.1583\n","Epoch [1/1], Step [200/938], Loss: 1.1005\n","Epoch [1/1], Step [300/938], Loss: 1.0393\n","Epoch [1/1], Step [400/938], Loss: 0.9561\n","Epoch [1/1], Step [500/938], Loss: 0.8175\n","Epoch [1/1], Step [600/938], Loss: 0.6860\n","Epoch [1/1], Step [700/938], Loss: 0.6300\n","Epoch [1/1], Step [800/938], Loss: 0.5495\n","Epoch [1/1], Step [900/938], Loss: 0.4614\n","Parameter containing:\n","tensor([[[[-0.9017, -0.7383, -0.6977],\n","          [-0.1580, -0.3442, -0.8040],\n","          [ 0.2455, -0.4987, -0.7098]]],\n","\n","\n","        [[[-1.0443,  0.0518,  0.8065],\n","          [-0.8094,  0.4188,  0.9858],\n","          [-0.8927,  0.0059,  0.9203]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.1448\n","Epoch [1/6], Step [200/938], Loss: 1.0087\n","Epoch [1/6], Step [300/938], Loss: 0.6498\n","Epoch [1/6], Step [400/938], Loss: 0.4125\n","Epoch [1/6], Step [500/938], Loss: 0.3329\n","Epoch [1/6], Step [600/938], Loss: 0.2942\n","Epoch [1/6], Step [700/938], Loss: 0.2740\n","Epoch [1/6], Step [800/938], Loss: 0.2674\n","Epoch [1/6], Step [900/938], Loss: 0.2435\n","Epoch [2/6], Step [100/938], Loss: 0.2266\n","Epoch [2/6], Step [200/938], Loss: 0.2209\n","Epoch [2/6], Step [300/938], Loss: 0.2232\n","Epoch [2/6], Step [400/938], Loss: 0.1965\n","Epoch [2/6], Step [500/938], Loss: 0.1920\n","Epoch [2/6], Step [600/938], Loss: 0.1869\n","Epoch [2/6], Step [700/938], Loss: 0.1904\n","Epoch [2/6], Step [800/938], Loss: 0.1872\n","Epoch [2/6], Step [900/938], Loss: 0.1801\n","Epoch [3/6], Step [100/938], Loss: 0.1735\n","Epoch [3/6], Step [200/938], Loss: 0.1717\n","Epoch [3/6], Step [300/938], Loss: 0.1800\n","Epoch [3/6], Step [400/938], Loss: 0.1580\n","Epoch [3/6], Step [500/938], Loss: 0.1561\n","Epoch [3/6], Step [600/938], Loss: 0.1564\n","Epoch [3/6], Step [700/938], Loss: 0.1570\n","Epoch [3/6], Step [800/938], Loss: 0.1544\n","Epoch [3/6], Step [900/938], Loss: 0.1511\n","Epoch [4/6], Step [100/938], Loss: 0.1518\n","Epoch [4/6], Step [200/938], Loss: 0.1476\n","Epoch [4/6], Step [300/938], Loss: 0.1573\n","Epoch [4/6], Step [400/938], Loss: 0.1384\n","Epoch [4/6], Step [500/938], Loss: 0.1374\n","Epoch [4/6], Step [600/938], Loss: 0.1404\n","Epoch [4/6], Step [700/938], Loss: 0.1377\n","Epoch [4/6], Step [800/938], Loss: 0.1365\n","Epoch [4/6], Step [900/938], Loss: 0.1343\n","Epoch [5/6], Step [100/938], Loss: 0.1389\n","Epoch [5/6], Step [200/938], Loss: 0.1340\n","Epoch [5/6], Step [300/938], Loss: 0.1427\n","Epoch [5/6], Step [400/938], Loss: 0.1262\n","Epoch [5/6], Step [500/938], Loss: 0.1258\n","Epoch [5/6], Step [600/938], Loss: 0.1298\n","Epoch [5/6], Step [700/938], Loss: 0.1254\n","Epoch [5/6], Step [800/938], Loss: 0.1249\n","Epoch [5/6], Step [900/938], Loss: 0.1231\n","Epoch [6/6], Step [100/938], Loss: 0.1294\n","Epoch [6/6], Step [200/938], Loss: 0.1241\n","Epoch [6/6], Step [300/938], Loss: 0.1320\n","Epoch [6/6], Step [400/938], Loss: 0.1177\n","Epoch [6/6], Step [500/938], Loss: 0.1176\n","Epoch [6/6], Step [600/938], Loss: 0.1213\n","Epoch [6/6], Step [700/938], Loss: 0.1161\n","Epoch [6/6], Step [800/938], Loss: 0.1162\n","Epoch [6/6], Step [900/938], Loss: 0.1150\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:14<06:10, 74.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0466\n","Epoch [2/6], Step [100/157], Loss: 0.3240\n","Epoch [3/6], Step [100/157], Loss: 0.2131\n","Epoch [4/6], Step [100/157], Loss: 0.1753\n","Epoch [5/6], Step [100/157], Loss: 0.1536\n","Epoch [6/6], Step [100/157], Loss: 0.1384\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:29<02:37, 39.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.8953\n","Epoch [2/6], Step [100/157], Loss: 0.2712\n","Epoch [3/6], Step [100/157], Loss: 0.1937\n","Epoch [4/6], Step [100/157], Loss: 0.1599\n","Epoch [5/6], Step [100/157], Loss: 0.1380\n","Epoch [6/6], Step [100/157], Loss: 0.1222\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:44<01:25, 28.36s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0038\n","Epoch [2/6], Step [100/157], Loss: 0.3091\n","Epoch [3/6], Step [100/157], Loss: 0.2181\n","Epoch [4/6], Step [100/157], Loss: 0.1804\n","Epoch [5/6], Step [100/157], Loss: 0.1536\n","Epoch [6/6], Step [100/157], Loss: 0.1309\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:59<00:46, 23.25s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9727\n","Epoch [2/6], Step [100/157], Loss: 0.2874\n","Epoch [3/6], Step [100/157], Loss: 0.2043\n","Epoch [4/6], Step [100/157], Loss: 0.1653\n","Epoch [5/6], Step [100/157], Loss: 0.1388\n","Epoch [6/6], Step [100/157], Loss: 0.1202\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [02:15<00:20, 20.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1167\n","Epoch [2/6], Step [100/157], Loss: 0.4318\n","Epoch [3/6], Step [100/157], Loss: 0.2177\n","Epoch [4/6], Step [100/157], Loss: 0.1627\n","Epoch [5/6], Step [100/157], Loss: 0.1352\n","Epoch [6/6], Step [100/157], Loss: 0.1181\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:30<00:00, 25.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0442\n","Epoch [1/1], Step [200/938], Loss: 0.4424\n","Epoch [1/1], Step [300/938], Loss: 0.2170\n","Epoch [1/1], Step [400/938], Loss: 0.1587\n","Epoch [1/1], Step [500/938], Loss: 0.1333\n","Epoch [1/1], Step [600/938], Loss: 0.1184\n","Epoch [1/1], Step [700/938], Loss: 0.1127\n","Epoch [1/1], Step [800/938], Loss: 0.1106\n","Epoch [1/1], Step [900/938], Loss: 0.1004\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.7833\n","Epoch [1/1], Step [200/938], Loss: 0.2597\n","Epoch [1/1], Step [300/938], Loss: 0.1706\n","Epoch [1/1], Step [400/938], Loss: 0.1295\n","Epoch [1/1], Step [500/938], Loss: 0.1086\n","Epoch [1/1], Step [600/938], Loss: 0.1019\n","Epoch [1/1], Step [700/938], Loss: 0.1012\n","Epoch [1/1], Step [800/938], Loss: 0.0966\n","Epoch [1/1], Step [900/938], Loss: 0.0913\n","Parameter containing:\n","tensor([[[[-0.7865,  0.1643,  0.5974],\n","          [-0.9511,  0.7649,  0.5460],\n","          [-0.1500,  0.6753,  0.7724]]],\n","\n","\n","        [[[ 0.7453,  0.7299,  1.0310],\n","          [-0.2181, -0.3043,  0.4900],\n","          [-0.7407, -0.7159, -0.3247]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.0887\n","Epoch [1/6], Step [200/938], Loss: 0.5051\n","Epoch [1/6], Step [300/938], Loss: 0.2421\n","Epoch [1/6], Step [400/938], Loss: 0.1733\n","Epoch [1/6], Step [500/938], Loss: 0.1446\n","Epoch [1/6], Step [600/938], Loss: 0.1288\n","Epoch [1/6], Step [700/938], Loss: 0.1216\n","Epoch [1/6], Step [800/938], Loss: 0.1184\n","Epoch [1/6], Step [900/938], Loss: 0.1152\n","Epoch [2/6], Step [100/938], Loss: 0.0969\n","Epoch [2/6], Step [200/938], Loss: 0.1007\n","Epoch [2/6], Step [300/938], Loss: 0.0987\n","Epoch [2/6], Step [400/938], Loss: 0.0907\n","Epoch [2/6], Step [500/938], Loss: 0.0812\n","Epoch [2/6], Step [600/938], Loss: 0.0825\n","Epoch [2/6], Step [700/938], Loss: 0.0798\n","Epoch [2/6], Step [800/938], Loss: 0.0820\n","Epoch [2/6], Step [900/938], Loss: 0.0826\n","Epoch [3/6], Step [100/938], Loss: 0.0722\n","Epoch [3/6], Step [200/938], Loss: 0.0769\n","Epoch [3/6], Step [300/938], Loss: 0.0782\n","Epoch [3/6], Step [400/938], Loss: 0.0761\n","Epoch [3/6], Step [500/938], Loss: 0.0655\n","Epoch [3/6], Step [600/938], Loss: 0.0687\n","Epoch [3/6], Step [700/938], Loss: 0.0650\n","Epoch [3/6], Step [800/938], Loss: 0.0691\n","Epoch [3/6], Step [900/938], Loss: 0.0689\n","Epoch [4/6], Step [100/938], Loss: 0.0618\n","Epoch [4/6], Step [200/938], Loss: 0.0659\n","Epoch [4/6], Step [300/938], Loss: 0.0684\n","Epoch [4/6], Step [400/938], Loss: 0.0691\n","Epoch [4/6], Step [500/938], Loss: 0.0574\n","Epoch [4/6], Step [600/938], Loss: 0.0610\n","Epoch [4/6], Step [700/938], Loss: 0.0570\n","Epoch [4/6], Step [800/938], Loss: 0.0621\n","Epoch [4/6], Step [900/938], Loss: 0.0614\n","Epoch [5/6], Step [100/938], Loss: 0.0558\n","Epoch [5/6], Step [200/938], Loss: 0.0595\n","Epoch [5/6], Step [300/938], Loss: 0.0618\n","Epoch [5/6], Step [400/938], Loss: 0.0643\n","Epoch [5/6], Step [500/938], Loss: 0.0517\n","Epoch [5/6], Step [600/938], Loss: 0.0549\n","Epoch [5/6], Step [700/938], Loss: 0.0516\n","Epoch [5/6], Step [800/938], Loss: 0.0568\n","Epoch [5/6], Step [900/938], Loss: 0.0555\n","Epoch [6/6], Step [100/938], Loss: 0.0512\n","Epoch [6/6], Step [200/938], Loss: 0.0543\n","Epoch [6/6], Step [300/938], Loss: 0.0569\n","Epoch [6/6], Step [400/938], Loss: 0.0601\n","Epoch [6/6], Step [500/938], Loss: 0.0473\n","Epoch [6/6], Step [600/938], Loss: 0.0508\n","Epoch [6/6], Step [700/938], Loss: 0.0475\n","Epoch [6/6], Step [800/938], Loss: 0.0531\n","Epoch [6/6], Step [900/938], Loss: 0.0512\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [00:49<04:06, 49.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1304\n","Epoch [2/6], Step [100/157], Loss: 0.6202\n","Epoch [3/6], Step [100/157], Loss: 0.3737\n","Epoch [4/6], Step [100/157], Loss: 0.3157\n","Epoch [5/6], Step [100/157], Loss: 0.2843\n","Epoch [6/6], Step [100/157], Loss: 0.2616\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [00:57<01:39, 24.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0312\n","Epoch [2/6], Step [100/157], Loss: 0.2910\n","Epoch [3/6], Step [100/157], Loss: 0.1973\n","Epoch [4/6], Step [100/157], Loss: 0.1628\n","Epoch [5/6], Step [100/157], Loss: 0.1423\n","Epoch [6/6], Step [100/157], Loss: 0.1280\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:05<00:52, 17.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0581\n","Epoch [2/6], Step [100/157], Loss: 0.2786\n","Epoch [3/6], Step [100/157], Loss: 0.2070\n","Epoch [4/6], Step [100/157], Loss: 0.1789\n","Epoch [5/6], Step [100/157], Loss: 0.1607\n","Epoch [6/6], Step [100/157], Loss: 0.1470\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:12<00:26, 13.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0243\n","Epoch [2/6], Step [100/157], Loss: 0.3350\n","Epoch [3/6], Step [100/157], Loss: 0.2414\n","Epoch [4/6], Step [100/157], Loss: 0.2066\n","Epoch [5/6], Step [100/157], Loss: 0.1845\n","Epoch [6/6], Step [100/157], Loss: 0.1684\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:20<00:11, 11.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1302\n","Epoch [2/6], Step [100/157], Loss: 0.4454\n","Epoch [3/6], Step [100/157], Loss: 0.2691\n","Epoch [4/6], Step [100/157], Loss: 0.2176\n","Epoch [5/6], Step [100/157], Loss: 0.1886\n","Epoch [6/6], Step [100/157], Loss: 0.1692\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [01:27<00:00, 14.59s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0241\n","Epoch [1/1], Step [200/938], Loss: 0.4240\n","Epoch [1/1], Step [300/938], Loss: 0.2654\n","Epoch [1/1], Step [400/938], Loss: 0.2097\n","Epoch [1/1], Step [500/938], Loss: 0.1800\n","Epoch [1/1], Step [600/938], Loss: 0.1621\n","Epoch [1/1], Step [700/938], Loss: 0.1545\n","Epoch [1/1], Step [800/938], Loss: 0.1487\n","Epoch [1/1], Step [900/938], Loss: 0.1313\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.9101\n","Epoch [1/1], Step [200/938], Loss: 0.4515\n","Epoch [1/1], Step [300/938], Loss: 0.3051\n","Epoch [1/1], Step [400/938], Loss: 0.2474\n","Epoch [1/1], Step [500/938], Loss: 0.2313\n","Epoch [1/1], Step [600/938], Loss: 0.2026\n","Epoch [1/1], Step [700/938], Loss: 0.1938\n","Epoch [1/1], Step [800/938], Loss: 0.1879\n","Epoch [1/1], Step [900/938], Loss: 0.1737\n","Parameter containing:\n","tensor([[[[ 0.6836,  1.0342,  0.5288],\n","          [ 0.2521,  0.6345, -0.5173],\n","          [-0.5178, -1.1978, -0.6153]]],\n","\n","\n","        [[[-0.9009, -0.7216, -0.8826],\n","          [-0.8635, -0.4790, -0.9172],\n","          [-1.0272, -0.9328, -0.6902]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 0.9770\n","Epoch [1/6], Step [200/938], Loss: 0.3744\n","Epoch [1/6], Step [300/938], Loss: 0.2659\n","Epoch [1/6], Step [400/938], Loss: 0.2129\n","Epoch [1/6], Step [500/938], Loss: 0.1867\n","Epoch [1/6], Step [600/938], Loss: 0.1703\n","Epoch [1/6], Step [700/938], Loss: 0.1705\n","Epoch [1/6], Step [800/938], Loss: 0.1689\n","Epoch [1/6], Step [900/938], Loss: 0.1541\n","Epoch [2/6], Step [100/938], Loss: 0.1377\n","Epoch [2/6], Step [200/938], Loss: 0.1308\n","Epoch [2/6], Step [300/938], Loss: 0.1309\n","Epoch [2/6], Step [400/938], Loss: 0.1151\n","Epoch [2/6], Step [500/938], Loss: 0.1026\n","Epoch [2/6], Step [600/938], Loss: 0.1024\n","Epoch [2/6], Step [700/938], Loss: 0.1011\n","Epoch [2/6], Step [800/938], Loss: 0.1042\n","Epoch [2/6], Step [900/938], Loss: 0.0960\n","Epoch [3/6], Step [100/938], Loss: 0.0905\n","Epoch [3/6], Step [200/938], Loss: 0.0906\n","Epoch [3/6], Step [300/938], Loss: 0.0914\n","Epoch [3/6], Step [400/938], Loss: 0.0829\n","Epoch [3/6], Step [500/938], Loss: 0.0739\n","Epoch [3/6], Step [600/938], Loss: 0.0780\n","Epoch [3/6], Step [700/938], Loss: 0.0767\n","Epoch [3/6], Step [800/938], Loss: 0.0788\n","Epoch [3/6], Step [900/938], Loss: 0.0737\n","Epoch [4/6], Step [100/938], Loss: 0.0720\n","Epoch [4/6], Step [200/938], Loss: 0.0731\n","Epoch [4/6], Step [300/938], Loss: 0.0754\n","Epoch [4/6], Step [400/938], Loss: 0.0687\n","Epoch [4/6], Step [500/938], Loss: 0.0617\n","Epoch [4/6], Step [600/938], Loss: 0.0662\n","Epoch [4/6], Step [700/938], Loss: 0.0657\n","Epoch [4/6], Step [800/938], Loss: 0.0659\n","Epoch [4/6], Step [900/938], Loss: 0.0627\n","Epoch [5/6], Step [100/938], Loss: 0.0623\n","Epoch [5/6], Step [200/938], Loss: 0.0628\n","Epoch [5/6], Step [300/938], Loss: 0.0665\n","Epoch [5/6], Step [400/938], Loss: 0.0607\n","Epoch [5/6], Step [500/938], Loss: 0.0542\n","Epoch [5/6], Step [600/938], Loss: 0.0588\n","Epoch [5/6], Step [700/938], Loss: 0.0585\n","Epoch [5/6], Step [800/938], Loss: 0.0581\n","Epoch [5/6], Step [900/938], Loss: 0.0558\n","Epoch [6/6], Step [100/938], Loss: 0.0562\n","Epoch [6/6], Step [200/938], Loss: 0.0557\n","Epoch [6/6], Step [300/938], Loss: 0.0605\n","Epoch [6/6], Step [400/938], Loss: 0.0552\n","Epoch [6/6], Step [500/938], Loss: 0.0492\n","Epoch [6/6], Step [600/938], Loss: 0.0536\n","Epoch [6/6], Step [700/938], Loss: 0.0531\n","Epoch [6/6], Step [800/938], Loss: 0.0524\n","Epoch [6/6], Step [900/938], Loss: 0.0508\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:03<05:19, 63.82s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0801\n","Epoch [2/6], Step [100/157], Loss: 0.3034\n","Epoch [3/6], Step [100/157], Loss: 0.1902\n","Epoch [4/6], Step [100/157], Loss: 0.1486\n","Epoch [5/6], Step [100/157], Loss: 0.1256\n","Epoch [6/6], Step [100/157], Loss: 0.1102\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:15<02:11, 32.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1065\n","Epoch [2/6], Step [100/157], Loss: 0.4310\n","Epoch [3/6], Step [100/157], Loss: 0.2678\n","Epoch [4/6], Step [100/157], Loss: 0.2204\n","Epoch [5/6], Step [100/157], Loss: 0.1930\n","Epoch [6/6], Step [100/157], Loss: 0.1751\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:25<01:07, 22.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9400\n","Epoch [2/6], Step [100/157], Loss: 0.2970\n","Epoch [3/6], Step [100/157], Loss: 0.2170\n","Epoch [4/6], Step [100/157], Loss: 0.1879\n","Epoch [5/6], Step [100/157], Loss: 0.1694\n","Epoch [6/6], Step [100/157], Loss: 0.1549\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:32<00:33, 16.69s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0085\n","Epoch [2/6], Step [100/157], Loss: 0.3316\n","Epoch [3/6], Step [100/157], Loss: 0.2094\n","Epoch [4/6], Step [100/157], Loss: 0.1691\n","Epoch [5/6], Step [100/157], Loss: 0.1472\n","Epoch [6/6], Step [100/157], Loss: 0.1329\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:45<00:15, 15.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1098\n","Epoch [2/6], Step [100/157], Loss: 0.3882\n","Epoch [3/6], Step [100/157], Loss: 0.1947\n","Epoch [4/6], Step [100/157], Loss: 0.1440\n","Epoch [5/6], Step [100/157], Loss: 0.1218\n","Epoch [6/6], Step [100/157], Loss: 0.1084\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [01:57<00:00, 19.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0501\n","Epoch [1/1], Step [200/938], Loss: 0.4958\n","Epoch [1/1], Step [300/938], Loss: 0.2982\n","Epoch [1/1], Step [400/938], Loss: 0.2304\n","Epoch [1/1], Step [500/938], Loss: 0.1932\n","Epoch [1/1], Step [600/938], Loss: 0.1696\n","Epoch [1/1], Step [700/938], Loss: 0.1651\n","Epoch [1/1], Step [800/938], Loss: 0.1497\n","Epoch [1/1], Step [900/938], Loss: 0.1388\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.6772\n","Epoch [1/1], Step [200/938], Loss: 0.2379\n","Epoch [1/1], Step [300/938], Loss: 0.1579\n","Epoch [1/1], Step [400/938], Loss: 0.1255\n","Epoch [1/1], Step [500/938], Loss: 0.1042\n","Epoch [1/1], Step [600/938], Loss: 0.0988\n","Epoch [1/1], Step [700/938], Loss: 0.0984\n","Epoch [1/1], Step [800/938], Loss: 0.0951\n","Epoch [1/1], Step [900/938], Loss: 0.0934\n","Parameter containing:\n","tensor([[[[-0.7049,  0.5691,  0.3324],\n","          [-0.8717,  0.1166,  0.8202],\n","          [-0.6184,  0.3286,  0.8265]]],\n","\n","\n","        [[[ 0.3214,  0.7817,  0.9154],\n","          [-0.4137,  0.0114,  0.1030],\n","          [-0.5569, -0.3967, -0.4924]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.0015\n","Epoch [1/6], Step [200/938], Loss: 0.4420\n","Epoch [1/6], Step [300/938], Loss: 0.2755\n","Epoch [1/6], Step [400/938], Loss: 0.2124\n","Epoch [1/6], Step [500/938], Loss: 0.1754\n","Epoch [1/6], Step [600/938], Loss: 0.1626\n","Epoch [1/6], Step [700/938], Loss: 0.1581\n","Epoch [1/6], Step [800/938], Loss: 0.1470\n","Epoch [1/6], Step [900/938], Loss: 0.1374\n","Epoch [2/6], Step [100/938], Loss: 0.1255\n","Epoch [2/6], Step [200/938], Loss: 0.1190\n","Epoch [2/6], Step [300/938], Loss: 0.1204\n","Epoch [2/6], Step [400/938], Loss: 0.1095\n","Epoch [2/6], Step [500/938], Loss: 0.0936\n","Epoch [2/6], Step [600/938], Loss: 0.0963\n","Epoch [2/6], Step [700/938], Loss: 0.0975\n","Epoch [2/6], Step [800/938], Loss: 0.0943\n","Epoch [2/6], Step [900/938], Loss: 0.0906\n","Epoch [3/6], Step [100/938], Loss: 0.0865\n","Epoch [3/6], Step [200/938], Loss: 0.0855\n","Epoch [3/6], Step [300/938], Loss: 0.0889\n","Epoch [3/6], Step [400/938], Loss: 0.0834\n","Epoch [3/6], Step [500/938], Loss: 0.0708\n","Epoch [3/6], Step [600/938], Loss: 0.0741\n","Epoch [3/6], Step [700/938], Loss: 0.0770\n","Epoch [3/6], Step [800/938], Loss: 0.0764\n","Epoch [3/6], Step [900/938], Loss: 0.0713\n","Epoch [4/6], Step [100/938], Loss: 0.0702\n","Epoch [4/6], Step [200/938], Loss: 0.0716\n","Epoch [4/6], Step [300/938], Loss: 0.0743\n","Epoch [4/6], Step [400/938], Loss: 0.0714\n","Epoch [4/6], Step [500/938], Loss: 0.0596\n","Epoch [4/6], Step [600/938], Loss: 0.0634\n","Epoch [4/6], Step [700/938], Loss: 0.0669\n","Epoch [4/6], Step [800/938], Loss: 0.0666\n","Epoch [4/6], Step [900/938], Loss: 0.0614\n","Epoch [5/6], Step [100/938], Loss: 0.0617\n","Epoch [5/6], Step [200/938], Loss: 0.0643\n","Epoch [5/6], Step [300/938], Loss: 0.0658\n","Epoch [5/6], Step [400/938], Loss: 0.0641\n","Epoch [5/6], Step [500/938], Loss: 0.0533\n","Epoch [5/6], Step [600/938], Loss: 0.0570\n","Epoch [5/6], Step [700/938], Loss: 0.0606\n","Epoch [5/6], Step [800/938], Loss: 0.0607\n","Epoch [5/6], Step [900/938], Loss: 0.0557\n","Epoch [6/6], Step [100/938], Loss: 0.0567\n","Epoch [6/6], Step [200/938], Loss: 0.0593\n","Epoch [6/6], Step [300/938], Loss: 0.0596\n","Epoch [6/6], Step [400/938], Loss: 0.0589\n","Epoch [6/6], Step [500/938], Loss: 0.0490\n","Epoch [6/6], Step [600/938], Loss: 0.0531\n","Epoch [6/6], Step [700/938], Loss: 0.0563\n","Epoch [6/6], Step [800/938], Loss: 0.0567\n","Epoch [6/6], Step [900/938], Loss: 0.0513\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:23<06:55, 83.06s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9748\n","Epoch [2/6], Step [100/157], Loss: 0.3220\n","Epoch [3/6], Step [100/157], Loss: 0.2298\n","Epoch [4/6], Step [100/157], Loss: 0.1911\n","Epoch [5/6], Step [100/157], Loss: 0.1673\n","Epoch [6/6], Step [100/157], Loss: 0.1497\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:38<02:53, 43.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0277\n","Epoch [2/6], Step [100/157], Loss: 0.3645\n","Epoch [3/6], Step [100/157], Loss: 0.2397\n","Epoch [4/6], Step [100/157], Loss: 0.1937\n","Epoch [5/6], Step [100/157], Loss: 0.1697\n","Epoch [6/6], Step [100/157], Loss: 0.1537\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:49<01:24, 28.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0404\n","Epoch [2/6], Step [100/157], Loss: 0.3265\n","Epoch [3/6], Step [100/157], Loss: 0.2035\n","Epoch [4/6], Step [100/157], Loss: 0.1620\n","Epoch [5/6], Step [100/157], Loss: 0.1371\n","Epoch [6/6], Step [100/157], Loss: 0.1201\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:56<00:39, 19.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9861\n","Epoch [2/6], Step [100/157], Loss: 0.2738\n","Epoch [3/6], Step [100/157], Loss: 0.1810\n","Epoch [4/6], Step [100/157], Loss: 0.1485\n","Epoch [5/6], Step [100/157], Loss: 0.1297\n","Epoch [6/6], Step [100/157], Loss: 0.1163\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [02:13<00:19, 19.05s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0184\n","Epoch [2/6], Step [100/157], Loss: 0.3033\n","Epoch [3/6], Step [100/157], Loss: 0.2007\n","Epoch [4/6], Step [100/157], Loss: 0.1607\n","Epoch [5/6], Step [100/157], Loss: 0.1381\n","Epoch [6/6], Step [100/157], Loss: 0.1228\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:29<00:00, 24.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0572\n","Epoch [1/1], Step [200/938], Loss: 0.5156\n","Epoch [1/1], Step [300/938], Loss: 0.3220\n","Epoch [1/1], Step [400/938], Loss: 0.2490\n","Epoch [1/1], Step [500/938], Loss: 0.2162\n","Epoch [1/1], Step [600/938], Loss: 0.1982\n","Epoch [1/1], Step [700/938], Loss: 0.1915\n","Epoch [1/1], Step [800/938], Loss: 0.1910\n","Epoch [1/1], Step [900/938], Loss: 0.1737\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.8463\n","Epoch [1/1], Step [200/938], Loss: 0.4204\n","Epoch [1/1], Step [300/938], Loss: 0.2859\n","Epoch [1/1], Step [400/938], Loss: 0.2216\n","Epoch [1/1], Step [500/938], Loss: 0.1871\n","Epoch [1/1], Step [600/938], Loss: 0.1642\n","Epoch [1/1], Step [700/938], Loss: 0.1605\n","Epoch [1/1], Step [800/938], Loss: 0.1549\n","Epoch [1/1], Step [900/938], Loss: 0.1339\n","Parameter containing:\n","tensor([[[[-0.3027, -0.1577, -0.9463],\n","          [ 0.2204,  0.3707, -0.7738],\n","          [ 0.8712,  0.9989,  0.6576]]],\n","\n","\n","        [[[ 0.8792,  0.5316,  0.1212],\n","          [ 0.9171, -0.2047, -0.6729],\n","          [ 0.8115, -0.1382, -0.5109]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.0955\n","Epoch [1/6], Step [200/938], Loss: 0.5853\n","Epoch [1/6], Step [300/938], Loss: 0.3859\n","Epoch [1/6], Step [400/938], Loss: 0.2907\n","Epoch [1/6], Step [500/938], Loss: 0.2413\n","Epoch [1/6], Step [600/938], Loss: 0.2182\n","Epoch [1/6], Step [700/938], Loss: 0.2045\n","Epoch [1/6], Step [800/938], Loss: 0.1997\n","Epoch [1/6], Step [900/938], Loss: 0.1849\n","Epoch [2/6], Step [100/938], Loss: 0.1607\n","Epoch [2/6], Step [200/938], Loss: 0.1574\n","Epoch [2/6], Step [300/938], Loss: 0.1604\n","Epoch [2/6], Step [400/938], Loss: 0.1425\n","Epoch [2/6], Step [500/938], Loss: 0.1229\n","Epoch [2/6], Step [600/938], Loss: 0.1245\n","Epoch [2/6], Step [700/938], Loss: 0.1188\n","Epoch [2/6], Step [800/938], Loss: 0.1220\n","Epoch [2/6], Step [900/938], Loss: 0.1182\n","Epoch [3/6], Step [100/938], Loss: 0.1048\n","Epoch [3/6], Step [200/938], Loss: 0.1038\n","Epoch [3/6], Step [300/938], Loss: 0.1066\n","Epoch [3/6], Step [400/938], Loss: 0.0999\n","Epoch [3/6], Step [500/938], Loss: 0.0845\n","Epoch [3/6], Step [600/938], Loss: 0.0881\n","Epoch [3/6], Step [700/938], Loss: 0.0857\n","Epoch [3/6], Step [800/938], Loss: 0.0883\n","Epoch [3/6], Step [900/938], Loss: 0.0888\n","Epoch [4/6], Step [100/938], Loss: 0.0796\n","Epoch [4/6], Step [200/938], Loss: 0.0798\n","Epoch [4/6], Step [300/938], Loss: 0.0819\n","Epoch [4/6], Step [400/938], Loss: 0.0794\n","Epoch [4/6], Step [500/938], Loss: 0.0666\n","Epoch [4/6], Step [600/938], Loss: 0.0711\n","Epoch [4/6], Step [700/938], Loss: 0.0703\n","Epoch [4/6], Step [800/938], Loss: 0.0721\n","Epoch [4/6], Step [900/938], Loss: 0.0733\n","Epoch [5/6], Step [100/938], Loss: 0.0669\n","Epoch [5/6], Step [200/938], Loss: 0.0684\n","Epoch [5/6], Step [300/938], Loss: 0.0700\n","Epoch [5/6], Step [400/938], Loss: 0.0688\n","Epoch [5/6], Step [500/938], Loss: 0.0565\n","Epoch [5/6], Step [600/938], Loss: 0.0616\n","Epoch [5/6], Step [700/938], Loss: 0.0613\n","Epoch [5/6], Step [800/938], Loss: 0.0632\n","Epoch [5/6], Step [900/938], Loss: 0.0647\n","Epoch [6/6], Step [100/938], Loss: 0.0595\n","Epoch [6/6], Step [200/938], Loss: 0.0621\n","Epoch [6/6], Step [300/938], Loss: 0.0631\n","Epoch [6/6], Step [400/938], Loss: 0.0621\n","Epoch [6/6], Step [500/938], Loss: 0.0503\n","Epoch [6/6], Step [600/938], Loss: 0.0556\n","Epoch [6/6], Step [700/938], Loss: 0.0556\n","Epoch [6/6], Step [800/938], Loss: 0.0575\n","Epoch [6/6], Step [900/938], Loss: 0.0590\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:26<07:12, 86.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0095\n","Epoch [2/6], Step [100/157], Loss: 0.3029\n","Epoch [3/6], Step [100/157], Loss: 0.2141\n","Epoch [4/6], Step [100/157], Loss: 0.1806\n","Epoch [5/6], Step [100/157], Loss: 0.1591\n","Epoch [6/6], Step [100/157], Loss: 0.1434\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:33<02:39, 39.79s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0200\n","Epoch [2/6], Step [100/157], Loss: 0.3317\n","Epoch [3/6], Step [100/157], Loss: 0.2172\n","Epoch [4/6], Step [100/157], Loss: 0.1742\n","Epoch [5/6], Step [100/157], Loss: 0.1487\n","Epoch [6/6], Step [100/157], Loss: 0.1305\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:41<01:15, 25.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0270\n","Epoch [2/6], Step [100/157], Loss: 0.3120\n","Epoch [3/6], Step [100/157], Loss: 0.2199\n","Epoch [4/6], Step [100/157], Loss: 0.1824\n","Epoch [5/6], Step [100/157], Loss: 0.1578\n","Epoch [6/6], Step [100/157], Loss: 0.1396\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:48<00:36, 18.15s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1112\n","Epoch [2/6], Step [100/157], Loss: 0.4830\n","Epoch [3/6], Step [100/157], Loss: 0.2722\n","Epoch [4/6], Step [100/157], Loss: 0.2036\n","Epoch [5/6], Step [100/157], Loss: 0.1739\n","Epoch [6/6], Step [100/157], Loss: 0.1571\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:55<00:14, 14.08s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0932\n","Epoch [2/6], Step [100/157], Loss: 0.3963\n","Epoch [3/6], Step [100/157], Loss: 0.2325\n","Epoch [4/6], Step [100/157], Loss: 0.1829\n","Epoch [5/6], Step [100/157], Loss: 0.1533\n","Epoch [6/6], Step [100/157], Loss: 0.1326\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:02<00:00, 20.34s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0359\n","Epoch [1/1], Step [200/938], Loss: 0.4509\n","Epoch [1/1], Step [300/938], Loss: 0.2597\n","Epoch [1/1], Step [400/938], Loss: 0.2084\n","Epoch [1/1], Step [500/938], Loss: 0.1719\n","Epoch [1/1], Step [600/938], Loss: 0.1513\n","Epoch [1/1], Step [700/938], Loss: 0.1451\n","Epoch [1/1], Step [800/938], Loss: 0.1438\n","Epoch [1/1], Step [900/938], Loss: 0.1245\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.8149\n","Epoch [1/1], Step [200/938], Loss: 0.3256\n","Epoch [1/1], Step [300/938], Loss: 0.2249\n","Epoch [1/1], Step [400/938], Loss: 0.1791\n","Epoch [1/1], Step [500/938], Loss: 0.1459\n","Epoch [1/1], Step [600/938], Loss: 0.1330\n","Epoch [1/1], Step [700/938], Loss: 0.1260\n","Epoch [1/1], Step [800/938], Loss: 0.1226\n","Epoch [1/1], Step [900/938], Loss: 0.1093\n","Parameter containing:\n","tensor([[[[-1.1823,  0.3888,  0.8526],\n","          [-0.0566,  0.7681,  0.5386],\n","          [ 0.4946,  0.8180, -0.2318]]],\n","\n","\n","        [[[ 0.2784, -0.3810, -1.0425],\n","          [ 0.6572,  0.2688, -0.6632],\n","          [ 0.8532,  0.7123,  0.0903]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 0.9840\n","Epoch [1/6], Step [200/938], Loss: 0.4002\n","Epoch [1/6], Step [300/938], Loss: 0.2784\n","Epoch [1/6], Step [400/938], Loss: 0.2227\n","Epoch [1/6], Step [500/938], Loss: 0.1945\n","Epoch [1/6], Step [600/938], Loss: 0.1765\n","Epoch [1/6], Step [700/938], Loss: 0.1677\n","Epoch [1/6], Step [800/938], Loss: 0.1619\n","Epoch [1/6], Step [900/938], Loss: 0.1470\n","Epoch [2/6], Step [100/938], Loss: 0.1358\n","Epoch [2/6], Step [200/938], Loss: 0.1301\n","Epoch [2/6], Step [300/938], Loss: 0.1281\n","Epoch [2/6], Step [400/938], Loss: 0.1115\n","Epoch [2/6], Step [500/938], Loss: 0.0980\n","Epoch [2/6], Step [600/938], Loss: 0.0972\n","Epoch [2/6], Step [700/938], Loss: 0.0966\n","Epoch [2/6], Step [800/938], Loss: 0.0982\n","Epoch [2/6], Step [900/938], Loss: 0.0931\n","Epoch [3/6], Step [100/938], Loss: 0.0898\n","Epoch [3/6], Step [200/938], Loss: 0.0884\n","Epoch [3/6], Step [300/938], Loss: 0.0881\n","Epoch [3/6], Step [400/938], Loss: 0.0802\n","Epoch [3/6], Step [500/938], Loss: 0.0671\n","Epoch [3/6], Step [600/938], Loss: 0.0692\n","Epoch [3/6], Step [700/938], Loss: 0.0727\n","Epoch [3/6], Step [800/938], Loss: 0.0740\n","Epoch [3/6], Step [900/938], Loss: 0.0719\n","Epoch [4/6], Step [100/938], Loss: 0.0697\n","Epoch [4/6], Step [200/938], Loss: 0.0699\n","Epoch [4/6], Step [300/938], Loss: 0.0706\n","Epoch [4/6], Step [400/938], Loss: 0.0658\n","Epoch [4/6], Step [500/938], Loss: 0.0538\n","Epoch [4/6], Step [600/938], Loss: 0.0557\n","Epoch [4/6], Step [700/938], Loss: 0.0607\n","Epoch [4/6], Step [800/938], Loss: 0.0616\n","Epoch [4/6], Step [900/938], Loss: 0.0608\n","Epoch [5/6], Step [100/938], Loss: 0.0586\n","Epoch [5/6], Step [200/938], Loss: 0.0598\n","Epoch [5/6], Step [300/938], Loss: 0.0604\n","Epoch [5/6], Step [400/938], Loss: 0.0568\n","Epoch [5/6], Step [500/938], Loss: 0.0472\n","Epoch [5/6], Step [600/938], Loss: 0.0485\n","Epoch [5/6], Step [700/938], Loss: 0.0535\n","Epoch [5/6], Step [800/938], Loss: 0.0541\n","Epoch [5/6], Step [900/938], Loss: 0.0540\n","Epoch [6/6], Step [100/938], Loss: 0.0520\n","Epoch [6/6], Step [200/938], Loss: 0.0535\n","Epoch [6/6], Step [300/938], Loss: 0.0542\n","Epoch [6/6], Step [400/938], Loss: 0.0507\n","Epoch [6/6], Step [500/938], Loss: 0.0434\n","Epoch [6/6], Step [600/938], Loss: 0.0441\n","Epoch [6/6], Step [700/938], Loss: 0.0490\n","Epoch [6/6], Step [800/938], Loss: 0.0495\n","Epoch [6/6], Step [900/938], Loss: 0.0497\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [00:37<03:07, 37.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1021\n","Epoch [2/6], Step [100/157], Loss: 0.3443\n","Epoch [3/6], Step [100/157], Loss: 0.1895\n","Epoch [4/6], Step [100/157], Loss: 0.1459\n","Epoch [5/6], Step [100/157], Loss: 0.1227\n","Epoch [6/6], Step [100/157], Loss: 0.1067\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [00:44<01:17, 19.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0994\n","Epoch [2/6], Step [100/157], Loss: 0.4321\n","Epoch [3/6], Step [100/157], Loss: 0.2452\n","Epoch [4/6], Step [100/157], Loss: 0.1889\n","Epoch [5/6], Step [100/157], Loss: 0.1550\n","Epoch [6/6], Step [100/157], Loss: 0.1343\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [00:50<00:40, 13.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0011\n","Epoch [2/6], Step [100/157], Loss: 0.3229\n","Epoch [3/6], Step [100/157], Loss: 0.2216\n","Epoch [4/6], Step [100/157], Loss: 0.1784\n","Epoch [5/6], Step [100/157], Loss: 0.1538\n","Epoch [6/6], Step [100/157], Loss: 0.1367\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:56<00:21, 10.65s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1056\n","Epoch [2/6], Step [100/157], Loss: 0.3765\n","Epoch [3/6], Step [100/157], Loss: 0.2100\n","Epoch [4/6], Step [100/157], Loss: 0.1635\n","Epoch [5/6], Step [100/157], Loss: 0.1361\n","Epoch [6/6], Step [100/157], Loss: 0.1194\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:11<00:12, 12.24s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0737\n","Epoch [2/6], Step [100/157], Loss: 0.3468\n","Epoch [3/6], Step [100/157], Loss: 0.2568\n","Epoch [4/6], Step [100/157], Loss: 0.2235\n","Epoch [5/6], Step [100/157], Loss: 0.2012\n","Epoch [6/6], Step [100/157], Loss: 0.1840\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [01:29<00:00, 14.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0675\n","Epoch [1/1], Step [200/938], Loss: 0.4741\n","Epoch [1/1], Step [300/938], Loss: 0.2669\n","Epoch [1/1], Step [400/938], Loss: 0.2152\n","Epoch [1/1], Step [500/938], Loss: 0.1792\n","Epoch [1/1], Step [600/938], Loss: 0.1616\n","Epoch [1/1], Step [700/938], Loss: 0.1508\n","Epoch [1/1], Step [800/938], Loss: 0.1540\n","Epoch [1/1], Step [900/938], Loss: 0.1373\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 1.1073\n","Epoch [1/1], Step [200/938], Loss: 0.8460\n","Epoch [1/1], Step [300/938], Loss: 0.5834\n","Epoch [1/1], Step [400/938], Loss: 0.4445\n","Epoch [1/1], Step [500/938], Loss: 0.3758\n","Epoch [1/1], Step [600/938], Loss: 0.3244\n","Epoch [1/1], Step [700/938], Loss: 0.3034\n","Epoch [1/1], Step [800/938], Loss: 0.2943\n","Epoch [1/1], Step [900/938], Loss: 0.2709\n","Parameter containing:\n","tensor([[[[-0.9314, -0.6449, -0.9592],\n","          [-0.4119, -0.8820, -0.4677],\n","          [-0.7947, -0.2505, -0.3759]]],\n","\n","\n","        [[[-0.7482, -0.7495, -0.8215],\n","          [-0.8516, -0.6664, -0.7261],\n","          [-0.6277, -0.7103, -0.8694]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 0.9782\n","Epoch [1/6], Step [200/938], Loss: 0.3871\n","Epoch [1/6], Step [300/938], Loss: 0.2354\n","Epoch [1/6], Step [400/938], Loss: 0.1761\n","Epoch [1/6], Step [500/938], Loss: 0.1600\n","Epoch [1/6], Step [600/938], Loss: 0.1417\n","Epoch [1/6], Step [700/938], Loss: 0.1349\n","Epoch [1/6], Step [800/938], Loss: 0.1364\n","Epoch [1/6], Step [900/938], Loss: 0.1222\n","Epoch [2/6], Step [100/938], Loss: 0.1141\n","Epoch [2/6], Step [200/938], Loss: 0.1163\n","Epoch [2/6], Step [300/938], Loss: 0.1093\n","Epoch [2/6], Step [400/938], Loss: 0.0961\n","Epoch [2/6], Step [500/938], Loss: 0.0943\n","Epoch [2/6], Step [600/938], Loss: 0.0928\n","Epoch [2/6], Step [700/938], Loss: 0.0903\n","Epoch [2/6], Step [800/938], Loss: 0.0956\n","Epoch [2/6], Step [900/938], Loss: 0.0907\n","Epoch [3/6], Step [100/938], Loss: 0.0854\n","Epoch [3/6], Step [200/938], Loss: 0.0918\n","Epoch [3/6], Step [300/938], Loss: 0.0869\n","Epoch [3/6], Step [400/938], Loss: 0.0776\n","Epoch [3/6], Step [500/938], Loss: 0.0777\n","Epoch [3/6], Step [600/938], Loss: 0.0771\n","Epoch [3/6], Step [700/938], Loss: 0.0763\n","Epoch [3/6], Step [800/938], Loss: 0.0809\n","Epoch [3/6], Step [900/938], Loss: 0.0790\n","Epoch [4/6], Step [100/938], Loss: 0.0740\n","Epoch [4/6], Step [200/938], Loss: 0.0806\n","Epoch [4/6], Step [300/938], Loss: 0.0767\n","Epoch [4/6], Step [400/938], Loss: 0.0692\n","Epoch [4/6], Step [500/938], Loss: 0.0697\n","Epoch [4/6], Step [600/938], Loss: 0.0684\n","Epoch [4/6], Step [700/938], Loss: 0.0683\n","Epoch [4/6], Step [800/938], Loss: 0.0719\n","Epoch [4/6], Step [900/938], Loss: 0.0712\n","Epoch [5/6], Step [100/938], Loss: 0.0672\n","Epoch [5/6], Step [200/938], Loss: 0.0737\n","Epoch [5/6], Step [300/938], Loss: 0.0701\n","Epoch [5/6], Step [400/938], Loss: 0.0654\n","Epoch [5/6], Step [500/938], Loss: 0.0641\n","Epoch [5/6], Step [600/938], Loss: 0.0627\n","Epoch [5/6], Step [700/938], Loss: 0.0627\n","Epoch [5/6], Step [800/938], Loss: 0.0657\n","Epoch [5/6], Step [900/938], Loss: 0.0662\n","Epoch [6/6], Step [100/938], Loss: 0.0620\n","Epoch [6/6], Step [200/938], Loss: 0.0687\n","Epoch [6/6], Step [300/938], Loss: 0.0653\n","Epoch [6/6], Step [400/938], Loss: 0.0611\n","Epoch [6/6], Step [500/938], Loss: 0.0600\n","Epoch [6/6], Step [600/938], Loss: 0.0586\n","Epoch [6/6], Step [700/938], Loss: 0.0584\n","Epoch [6/6], Step [800/938], Loss: 0.0609\n","Epoch [6/6], Step [900/938], Loss: 0.0624\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [00:52<04:24, 52.90s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0218\n","Epoch [2/6], Step [100/157], Loss: 0.3126\n","Epoch [3/6], Step [100/157], Loss: 0.2202\n","Epoch [4/6], Step [100/157], Loss: 0.1871\n","Epoch [5/6], Step [100/157], Loss: 0.1662\n","Epoch [6/6], Step [100/157], Loss: 0.1513\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [00:59<01:42, 25.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0477\n","Epoch [2/6], Step [100/157], Loss: 0.3700\n","Epoch [3/6], Step [100/157], Loss: 0.2554\n","Epoch [4/6], Step [100/157], Loss: 0.2151\n","Epoch [5/6], Step [100/157], Loss: 0.1916\n","Epoch [6/6], Step [100/157], Loss: 0.1748\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:14<01:02, 20.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0453\n","Epoch [2/6], Step [100/157], Loss: 0.2698\n","Epoch [3/6], Step [100/157], Loss: 0.1669\n","Epoch [4/6], Step [100/157], Loss: 0.1336\n","Epoch [5/6], Step [100/157], Loss: 0.1156\n","Epoch [6/6], Step [100/157], Loss: 0.1038\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:29<00:37, 18.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9885\n","Epoch [2/6], Step [100/157], Loss: 0.2861\n","Epoch [3/6], Step [100/157], Loss: 0.2094\n","Epoch [4/6], Step [100/157], Loss: 0.1804\n","Epoch [5/6], Step [100/157], Loss: 0.1624\n","Epoch [6/6], Step [100/157], Loss: 0.1488\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:45<00:17, 17.72s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9602\n","Epoch [2/6], Step [100/157], Loss: 0.2739\n","Epoch [3/6], Step [100/157], Loss: 0.2010\n","Epoch [4/6], Step [100/157], Loss: 0.1699\n","Epoch [5/6], Step [100/157], Loss: 0.1492\n","Epoch [6/6], Step [100/157], Loss: 0.1336\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:01<00:00, 20.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 0.9415\n","Epoch [1/1], Step [200/938], Loss: 0.3738\n","Epoch [1/1], Step [300/938], Loss: 0.2734\n","Epoch [1/1], Step [400/938], Loss: 0.2264\n","Epoch [1/1], Step [500/938], Loss: 0.2069\n","Epoch [1/1], Step [600/938], Loss: 0.1902\n","Epoch [1/1], Step [700/938], Loss: 0.1869\n","Epoch [1/1], Step [800/938], Loss: 0.1824\n","Epoch [1/1], Step [900/938], Loss: 0.1761\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 1.0045\n","Epoch [1/1], Step [200/938], Loss: 0.5622\n","Epoch [1/1], Step [300/938], Loss: 0.3516\n","Epoch [1/1], Step [400/938], Loss: 0.2709\n","Epoch [1/1], Step [500/938], Loss: 0.2276\n","Epoch [1/1], Step [600/938], Loss: 0.2138\n","Epoch [1/1], Step [700/938], Loss: 0.1982\n","Epoch [1/1], Step [800/938], Loss: 0.1935\n","Epoch [1/1], Step [900/938], Loss: 0.1799\n","Parameter containing:\n","tensor([[[[-0.0162, -0.4688, -0.1609],\n","          [-0.7438, -0.2417, -0.7547],\n","          [-0.7090, -0.5214, -0.7342]]],\n","\n","\n","        [[[ 0.6298,  0.5559,  0.8036],\n","          [-0.3225,  0.4599,  0.3359],\n","          [-1.0403, -0.7061, -0.4456]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 1.0468\n","Epoch [1/6], Step [200/938], Loss: 0.4559\n","Epoch [1/6], Step [300/938], Loss: 0.2679\n","Epoch [1/6], Step [400/938], Loss: 0.1954\n","Epoch [1/6], Step [500/938], Loss: 0.1662\n","Epoch [1/6], Step [600/938], Loss: 0.1433\n","Epoch [1/6], Step [700/938], Loss: 0.1345\n","Epoch [1/6], Step [800/938], Loss: 0.1294\n","Epoch [1/6], Step [900/938], Loss: 0.1148\n","Epoch [2/6], Step [100/938], Loss: 0.0955\n","Epoch [2/6], Step [200/938], Loss: 0.0957\n","Epoch [2/6], Step [300/938], Loss: 0.0957\n","Epoch [2/6], Step [400/938], Loss: 0.0875\n","Epoch [2/6], Step [500/938], Loss: 0.0792\n","Epoch [2/6], Step [600/938], Loss: 0.0778\n","Epoch [2/6], Step [700/938], Loss: 0.0790\n","Epoch [2/6], Step [800/938], Loss: 0.0810\n","Epoch [2/6], Step [900/938], Loss: 0.0758\n","Epoch [3/6], Step [100/938], Loss: 0.0648\n","Epoch [3/6], Step [200/938], Loss: 0.0684\n","Epoch [3/6], Step [300/938], Loss: 0.0714\n","Epoch [3/6], Step [400/938], Loss: 0.0709\n","Epoch [3/6], Step [500/938], Loss: 0.0601\n","Epoch [3/6], Step [600/938], Loss: 0.0634\n","Epoch [3/6], Step [700/938], Loss: 0.0649\n","Epoch [3/6], Step [800/938], Loss: 0.0667\n","Epoch [3/6], Step [900/938], Loss: 0.0628\n","Epoch [4/6], Step [100/938], Loss: 0.0552\n","Epoch [4/6], Step [200/938], Loss: 0.0585\n","Epoch [4/6], Step [300/938], Loss: 0.0620\n","Epoch [4/6], Step [400/938], Loss: 0.0641\n","Epoch [4/6], Step [500/938], Loss: 0.0523\n","Epoch [4/6], Step [600/938], Loss: 0.0571\n","Epoch [4/6], Step [700/938], Loss: 0.0581\n","Epoch [4/6], Step [800/938], Loss: 0.0597\n","Epoch [4/6], Step [900/938], Loss: 0.0561\n","Epoch [5/6], Step [100/938], Loss: 0.0504\n","Epoch [5/6], Step [200/938], Loss: 0.0529\n","Epoch [5/6], Step [300/938], Loss: 0.0565\n","Epoch [5/6], Step [400/938], Loss: 0.0598\n","Epoch [5/6], Step [500/938], Loss: 0.0479\n","Epoch [5/6], Step [600/938], Loss: 0.0529\n","Epoch [5/6], Step [700/938], Loss: 0.0536\n","Epoch [5/6], Step [800/938], Loss: 0.0551\n","Epoch [5/6], Step [900/938], Loss: 0.0518\n","Epoch [6/6], Step [100/938], Loss: 0.0473\n","Epoch [6/6], Step [200/938], Loss: 0.0490\n","Epoch [6/6], Step [300/938], Loss: 0.0524\n","Epoch [6/6], Step [400/938], Loss: 0.0565\n","Epoch [6/6], Step [500/938], Loss: 0.0445\n","Epoch [6/6], Step [600/938], Loss: 0.0500\n","Epoch [6/6], Step [700/938], Loss: 0.0505\n","Epoch [6/6], Step [800/938], Loss: 0.0518\n","Epoch [6/6], Step [900/938], Loss: 0.0492\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:12<06:02, 72.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1337\n","Epoch [2/6], Step [100/157], Loss: 0.6560\n","Epoch [3/6], Step [100/157], Loss: 0.3441\n","Epoch [4/6], Step [100/157], Loss: 0.2777\n","Epoch [5/6], Step [100/157], Loss: 0.2399\n","Epoch [6/6], Step [100/157], Loss: 0.2136\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:22<02:22, 35.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 0.9822\n","Epoch [2/6], Step [100/157], Loss: 0.2740\n","Epoch [3/6], Step [100/157], Loss: 0.1948\n","Epoch [4/6], Step [100/157], Loss: 0.1607\n","Epoch [5/6], Step [100/157], Loss: 0.1388\n","Epoch [6/6], Step [100/157], Loss: 0.1224\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:30<01:09, 23.16s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1149\n","Epoch [2/6], Step [100/157], Loss: 0.4509\n","Epoch [3/6], Step [100/157], Loss: 0.2775\n","Epoch [4/6], Step [100/157], Loss: 0.2351\n","Epoch [5/6], Step [100/157], Loss: 0.2112\n","Epoch [6/6], Step [100/157], Loss: 0.1936\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:45<00:40, 20.08s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0493\n","Epoch [2/6], Step [100/157], Loss: 0.3061\n","Epoch [3/6], Step [100/157], Loss: 0.1823\n","Epoch [4/6], Step [100/157], Loss: 0.1406\n","Epoch [5/6], Step [100/157], Loss: 0.1191\n","Epoch [6/6], Step [100/157], Loss: 0.1049\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:59<00:17, 17.76s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0275\n","Epoch [2/6], Step [100/157], Loss: 0.2670\n","Epoch [3/6], Step [100/157], Loss: 0.1721\n","Epoch [4/6], Step [100/157], Loss: 0.1402\n","Epoch [5/6], Step [100/157], Loss: 0.1227\n","Epoch [6/6], Step [100/157], Loss: 0.1112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:16<00:00, 22.83s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.0387\n","Epoch [1/1], Step [200/938], Loss: 0.4818\n","Epoch [1/1], Step [300/938], Loss: 0.3129\n","Epoch [1/1], Step [400/938], Loss: 0.2406\n","Epoch [1/1], Step [500/938], Loss: 0.2077\n","Epoch [1/1], Step [600/938], Loss: 0.1870\n","Epoch [1/1], Step [700/938], Loss: 0.1818\n","Epoch [1/1], Step [800/938], Loss: 0.1704\n","Epoch [1/1], Step [900/938], Loss: 0.1560\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 1.0137\n","Epoch [1/1], Step [200/938], Loss: 0.5685\n","Epoch [1/1], Step [300/938], Loss: 0.3933\n","Epoch [1/1], Step [400/938], Loss: 0.3136\n","Epoch [1/1], Step [500/938], Loss: 0.2710\n","Epoch [1/1], Step [600/938], Loss: 0.2501\n","Epoch [1/1], Step [700/938], Loss: 0.2425\n","Epoch [1/1], Step [800/938], Loss: 0.2322\n","Epoch [1/1], Step [900/938], Loss: 0.2210\n","Parameter containing:\n","tensor([[[[ 0.3915,  0.3481,  0.2197],\n","          [ 0.9465,  0.7394, -0.4843],\n","          [ 0.9254,  0.3598, -1.3544]]],\n","\n","\n","        [[[-0.9108, -0.7681, -0.6594],\n","          [-0.8121, -0.8514, -0.7511],\n","          [-0.6621, -0.6424,  0.3052]]]], requires_grad=True)\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/6 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/938], Loss: 0.9984\n","Epoch [1/6], Step [200/938], Loss: 0.4003\n","Epoch [1/6], Step [300/938], Loss: 0.2785\n","Epoch [1/6], Step [400/938], Loss: 0.2272\n","Epoch [1/6], Step [500/938], Loss: 0.2087\n","Epoch [1/6], Step [600/938], Loss: 0.1922\n","Epoch [1/6], Step [700/938], Loss: 0.1848\n","Epoch [1/6], Step [800/938], Loss: 0.1778\n","Epoch [1/6], Step [900/938], Loss: 0.1657\n","Epoch [2/6], Step [100/938], Loss: 0.1469\n","Epoch [2/6], Step [200/938], Loss: 0.1479\n","Epoch [2/6], Step [300/938], Loss: 0.1430\n","Epoch [2/6], Step [400/938], Loss: 0.1308\n","Epoch [2/6], Step [500/938], Loss: 0.1211\n","Epoch [2/6], Step [600/938], Loss: 0.1193\n","Epoch [2/6], Step [700/938], Loss: 0.1160\n","Epoch [2/6], Step [800/938], Loss: 0.1162\n","Epoch [2/6], Step [900/938], Loss: 0.1134\n","Epoch [3/6], Step [100/938], Loss: 0.1007\n","Epoch [3/6], Step [200/938], Loss: 0.1029\n","Epoch [3/6], Step [300/938], Loss: 0.1000\n","Epoch [3/6], Step [400/938], Loss: 0.0950\n","Epoch [3/6], Step [500/938], Loss: 0.0859\n","Epoch [3/6], Step [600/938], Loss: 0.0877\n","Epoch [3/6], Step [700/938], Loss: 0.0839\n","Epoch [3/6], Step [800/938], Loss: 0.0846\n","Epoch [3/6], Step [900/938], Loss: 0.0868\n","Epoch [4/6], Step [100/938], Loss: 0.0782\n","Epoch [4/6], Step [200/938], Loss: 0.0795\n","Epoch [4/6], Step [300/938], Loss: 0.0799\n","Epoch [4/6], Step [400/938], Loss: 0.0774\n","Epoch [4/6], Step [500/938], Loss: 0.0689\n","Epoch [4/6], Step [600/938], Loss: 0.0710\n","Epoch [4/6], Step [700/938], Loss: 0.0666\n","Epoch [4/6], Step [800/938], Loss: 0.0678\n","Epoch [4/6], Step [900/938], Loss: 0.0713\n","Epoch [5/6], Step [100/938], Loss: 0.0660\n","Epoch [5/6], Step [200/938], Loss: 0.0661\n","Epoch [5/6], Step [300/938], Loss: 0.0680\n","Epoch [5/6], Step [400/938], Loss: 0.0675\n","Epoch [5/6], Step [500/938], Loss: 0.0591\n","Epoch [5/6], Step [600/938], Loss: 0.0607\n","Epoch [5/6], Step [700/938], Loss: 0.0566\n","Epoch [5/6], Step [800/938], Loss: 0.0576\n","Epoch [5/6], Step [900/938], Loss: 0.0619\n","Epoch [6/6], Step [100/938], Loss: 0.0581\n","Epoch [6/6], Step [200/938], Loss: 0.0580\n","Epoch [6/6], Step [300/938], Loss: 0.0604\n","Epoch [6/6], Step [400/938], Loss: 0.0609\n","Epoch [6/6], Step [500/938], Loss: 0.0531\n","Epoch [6/6], Step [600/938], Loss: 0.0540\n","Epoch [6/6], Step [700/938], Loss: 0.0509\n","Epoch [6/6], Step [800/938], Loss: 0.0512\n","Epoch [6/6], Step [900/938], Loss: 0.0552\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [00:57<04:49, 57.82s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.1022\n","Epoch [2/6], Step [100/157], Loss: 0.3889\n","Epoch [3/6], Step [100/157], Loss: 0.2558\n","Epoch [4/6], Step [100/157], Loss: 0.2155\n","Epoch [5/6], Step [100/157], Loss: 0.1906\n","Epoch [6/6], Step [100/157], Loss: 0.1728\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [01:11<02:06, 31.64s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0839\n","Epoch [2/6], Step [100/157], Loss: 0.3845\n","Epoch [3/6], Step [100/157], Loss: 0.2404\n","Epoch [4/6], Step [100/157], Loss: 0.1888\n","Epoch [5/6], Step [100/157], Loss: 0.1582\n","Epoch [6/6], Step [100/157], Loss: 0.1377\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [01:26<01:12, 24.17s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0656\n","Epoch [2/6], Step [100/157], Loss: 0.3060\n","Epoch [3/6], Step [100/157], Loss: 0.1982\n","Epoch [4/6], Step [100/157], Loss: 0.1609\n","Epoch [5/6], Step [100/157], Loss: 0.1422\n","Epoch [6/6], Step [100/157], Loss: 0.1303\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [01:41<00:41, 20.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0393\n","Epoch [2/6], Step [100/157], Loss: 0.2724\n","Epoch [3/6], Step [100/157], Loss: 0.1917\n","Epoch [4/6], Step [100/157], Loss: 0.1542\n","Epoch [5/6], Step [100/157], Loss: 0.1290\n","Epoch [6/6], Step [100/157], Loss: 0.1109\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [01:56<00:18, 18.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/6], Step [100/157], Loss: 1.0609\n","Epoch [2/6], Step [100/157], Loss: 0.3906\n","Epoch [3/6], Step [100/157], Loss: 0.2549\n","Epoch [4/6], Step [100/157], Loss: 0.2118\n","Epoch [5/6], Step [100/157], Loss: 0.1875\n","Epoch [6/6], Step [100/157], Loss: 0.1718\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [02:11<00:00, 21.98s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [100/938], Loss: 1.1243\n","Epoch [1/1], Step [200/938], Loss: 0.7703\n","Epoch [1/1], Step [300/938], Loss: 0.4517\n","Epoch [1/1], Step [400/938], Loss: 0.3496\n","Epoch [1/1], Step [500/938], Loss: 0.3244\n","Epoch [1/1], Step [600/938], Loss: 0.2728\n","Epoch [1/1], Step [700/938], Loss: 0.2627\n","Epoch [1/1], Step [800/938], Loss: 0.2522\n","Epoch [1/1], Step [900/938], Loss: 0.2381\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","torch.Size([8, 3, 3])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 2, 28, 28]              20\n","              ReLU-2            [-1, 2, 28, 28]               0\n","         MaxPool2d-3            [-1, 2, 14, 14]               0\n","            Conv2d-4            [-1, 4, 14, 14]              76\n","              ReLU-5            [-1, 4, 14, 14]               0\n","         MaxPool2d-6              [-1, 4, 7, 7]               0\n","            Linear-7                   [-1, 16]           3,152\n","              ReLU-8                   [-1, 16]               0\n","            Linear-9                   [-1, 10]             170\n","================================================================\n","Total params: 3,418\n","Trainable params: 3,418\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.04\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n","odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n","Epoch [1/1], Step [100/938], Loss: 0.7671\n","Epoch [1/1], Step [200/938], Loss: 0.2918\n","Epoch [1/1], Step [300/938], Loss: 0.2340\n","Epoch [1/1], Step [400/938], Loss: 0.1825\n","Epoch [1/1], Step [500/938], Loss: 0.1533\n","Epoch [1/1], Step [600/938], Loss: 0.1334\n","Epoch [1/1], Step [700/938], Loss: 0.1289\n","Epoch [1/1], Step [800/938], Loss: 0.1163\n","Epoch [1/1], Step [900/938], Loss: 0.1193\n","Parameter containing:\n","tensor([[[[-0.8132, -0.3740,  0.2793],\n","          [-0.6374,  0.4582,  0.9887],\n","          [-0.1694,  0.8612,  0.6649]]],\n","\n","\n","        [[[-0.4216, -0.6423, -0.8261],\n","          [-0.2009, -0.2301,  0.5279],\n","          [ 0.8658,  0.5855,  0.4729]]]], requires_grad=True)\n"]}],"source":["\n","\n","cosine_similarities = []\n","cosine_rand_accuracies = []\n","cosine_warm_accuracies = []\n","cos_list_of_indexes = []\n","\n","for i in range(10):\n","\n","    rand_model, cos_models, _ = generate_models()\n","    #cos_models = cos_models[0]\n","    rand_optimizer, cos_optimizers = gen_optimizers(rand_model, cos_models)\n","    print(cos_optimizers[0])\n","\n","\n","    train_models(cos_models, cos_optimizers)\n","    train_rand_model(rand_model, rand_optimizer)\n","    similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10 = compare_filters(cos_models, metrics='overall_sim')\n","    indexes = get_max_index(similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10)\n","    cos_list_of_indexes.append(indexes)\n","    selected_filters = select_filters(cos_models, indexes)\n","    model_warm_start = gen_warm_start_model()\n","    initial_params, final_params = train_warm_start_model(model_warm_start)\n","    accuracy = test_warm_start_model(model_warm_start)\n","    rand_accuracy = test_model(rand_model)\n","\n","    cosine_similarities.append([similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10])\n","    cosine_rand_accuracies.append(rand_accuracy)\n","    cosine_warm_accuracies.append(accuracy)\n","\n","\n","\n","\n","pearson_similarities = []\n","pearson_rand_accuracies = []\n","pearson_warm_accuracies = []\n","pear_list_of_indexes = []\n","\n","for i in range(10):\n","\n","    pear_models = generate_models()\n","    pear_models = pear_models[0]\n","    pear_optimizers = gen_optimizers(pear_models)\n","    print(pear_optimizers[0])\n","    \n","    train_models(pear_models, pear_optimizers)\n","    similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10 = compare_filters(pear_models, metrics='pearson_coeff')\n","    indexes = get_max_index(similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10)\n","    pear_list_of_indexes.append(indexes)\n","    selected_filters = select_filters(pear_models, indexes)\n","    model_warm_start = gen_warm_start_model()\n","    initial_params, final_params = train_warm_start_model(model_warm_start)\n","    accuracy = test_warm_start_model(model_warm_start)\n","    #rand_accuracy = test_model(pear_models[0])\n","\n","    pearson_similarities.append([similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10])\n","    #pearson_rand_accuracies.append(rand_accuracy)\n","    pearson_warm_accuracies.append(accuracy)\n","\n","\n","\n","frob_norm_similarities = []\n","frob_norm_rand_accuracies = []\n","frob_norm_warm_accuracies = []\n","frob_list_of_indexes = []\n","\n","for i in range(10):\n","\n","    frob_models = generate_models()\n","    frob_models = frob_models[0]\n","    frob_optimizers = gen_optimizers(frob_models)\n","    print(frob_optimizers[0])\n","        \n","    train_models(frob_models, frob_optimizers)\n","    similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10 = compare_filters(frob_models, metrics='frob_norm')\n","    indexes = get_max_index(similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10)\n","    frob_list_of_indexes.append(indexes)\n","    selected_filters = select_filters(frob_models, indexes)\n","    model_warm_start = gen_warm_start_model()\n","    initial_params, final_params = train_warm_start_model(model_warm_start)\n","    accuracy = test_warm_start_model(model_warm_start)\n","    #rand_accuracy = test_model(frob_models[0])\n","\n","    frob_norm_similarities.append([similarity_scores_1, similarity_scores_2, similarity_scores_3, similarity_scores_4, similarity_scores_5, similarity_scores_6, similarity_scores_7, similarity_scores_8, similarity_scores_9, similarity_scores_10])\n","    #frob_norm_rand_accuracies.append(rand_accuracy)\n","    frob_norm_warm_accuracies.append(accuracy)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cosine similarity average accuracy: 89.55\n","Average random init accuracy: 91.597\n"]}],"source":["cosine_avg_acc = np.mean(cosine_warm_accuracies)\n","cosine_avg_rand_acc = np.mean(cosine_rand_accuracies)\n","#pearson_avg_acc = np.mean(pearson_warm_accuracies)\n","#pearson_avg_rand_acc = np.mean(pearson_rand_accuracies)\n","#frob_norm_avg_acc = np.mean(frob_norm_warm_accuracies)\n","#frob_norm_avg_rand_acc = np.mean(frob_norm_rand_accuracies)\n","\n","print(\"Cosine similarity average accuracy:\", cosine_avg_acc)\n","print(\"Average random init accuracy:\", cosine_avg_rand_acc)\n","# print(\"Pearson coefficient average accuracy:\", pearson_avg_acc)\n","# print(\"Average random init accuracy:\", pearson_avg_rand_acc)\n","# print(\"Frobenius norm average accuracy:\", frob_norm_avg_acc)\n","# print(\"Average random init accuracy:\", frob_norm_avg_rand_acc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cosine_avg_acc = np.mean(cosine_warm_accuracies)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(10, 10, 15)\n"]}],"source":["cosine_similarities = np.array(cosine_similarities)\n","print(cosine_similarities.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cosine similarity average: [0.32496548 0.35777047 0.32474437 0.30338407 0.30188456 0.31750953\n"," 0.32828334 0.3339134  0.33751735 0.32972413]\n","Pearson coefficient average: [0.35488217 0.30580742 0.29597189 0.2724866  0.31063052 0.31942968\n"," 0.32798588 0.2913928  0.3117596  0.314792  ]\n","Frobenius norm average: [1.2457141  1.3444834  0.79320043 0.7922893  0.810864   0.8224125\n"," 0.8526828  0.8050327  0.79380804 0.8471337 ]\n","Cosine similarity std: [0.2324773  0.24733762 0.21236593 0.20830548 0.2060729  0.2034407\n"," 0.22397177 0.22980148 0.21245918 0.24268942]\n","Pearson coefficient std: [0.21401942 0.22137701 0.20556037 0.20266949 0.23194205 0.20776374\n"," 0.21713388 0.19433722 0.21440426 0.21362927]\n","Frobenius norm std: [0.2990714  0.27728248 0.20766515 0.18816832 0.20266166 0.19012426\n"," 0.18869406 0.20239906 0.21184993 0.20122473]\n"]}],"source":["avg_cosine_sim = np.mean(cosine_similarities, axis=(0,2))\n","avg_pearson_sim = np.mean(pearson_similarities, axis=(0,2))\n","avg_frob_norm_sim = np.mean(frob_norm_similarities, axis=(0,2))\n","\n","\n","std_cosine_sim = np.std(cosine_similarities, axis=(0,2))\n","std_pearson_sim = np.std(pearson_similarities, axis=(0,2))\n","std_frob_norm_sim = np.std(frob_norm_similarities, axis=(0,2))\n","\n","\n","print(\"Cosine similarity average:\", avg_cosine_sim)\n","print(\"Pearson coefficient average:\", avg_pearson_sim)\n","print(\"Frobenius norm average:\", avg_frob_norm_sim)\n","\n","print(\"Cosine similarity std:\", std_cosine_sim)\n","print(\"Pearson coefficient std:\", std_pearson_sim)\n","print(\"Frobenius norm std:\", std_frob_norm_sim)\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'cos_list_of_indexes' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m----> 4\u001b[0m cos_list_of_indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcos_list_of_indexes\u001b[49m)\n\u001b[1;32m      5\u001b[0m mode_cos \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mmode(cos_list_of_indexes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mode_cos)\n","\u001b[0;31mNameError\u001b[0m: name 'cos_list_of_indexes' is not defined"]}],"source":["from scipy import stats\n","\n","\n","cos_list_of_indexes = np.array(cos_list_of_indexes)\n","mode_cos = stats.mode(cos_list_of_indexes, axis=1)\n","print(mode_cos)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"]},{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m sims \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m sims_rand \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m final_rand_params \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m      8\u001b[0m initial_rand_filters \u001b[38;5;241m=\u001b[39m [initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m], initial_rand_parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m      9\u001b[0m final_rand_filters \u001b[38;5;241m=\u001b[39m [final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m], final_rand_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m1\u001b[39m]]\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["print(initial_params.keys())\n","initial_filters = [initial_params['conv1.weight'][0], initial_params['conv1.weight'][1], initial_params['conv2.weight'][0][0], initial_params['conv2.weight'][0][1], initial_params['conv2.weight'][1][0], initial_params['conv2.weight'][1][1], initial_params['conv2.weight'][2][0], initial_params['conv2.weight'][2][1], initial_params['conv2.weight'][3][0], initial_params['conv2.weight'][3][1]]\n","final_filters = [final_params['conv1.weight'][0], final_params['conv1.weight'][1], final_params['conv2.weight'][0][0], final_params['conv2.weight'][0][1], final_params['conv2.weight'][1][0], final_params['conv2.weight'][1][1], final_params['conv2.weight'][2][0], final_params['conv2.weight'][2][1], final_params['conv2.weight'][3][0], final_params['conv2.weight'][3][1]]\n","sims = []\n","sims_rand = []\n","\n","final_rand_params = model.state_dict()\n","initial_rand_filters = [initial_rand_parms['conv1.weight'][0], initial_rand_parms['conv1.weight'][1], initial_rand_parms['conv2.weight'][0][0], initial_rand_parms['conv2.weight'][0][1], initial_rand_parms['conv2.weight'][1][0], initial_rand_parms['conv2.weight'][1][1], initial_rand_parms['conv2.weight'][2][0], initial_rand_parms['conv2.weight'][2][1], initial_rand_parms['conv2.weight'][3][0], initial_rand_parms['conv2.weight'][3][1]]\n","final_rand_filters = [final_rand_params['conv1.weight'][0], final_rand_params['conv1.weight'][1], final_rand_params['conv2.weight'][0][0], final_rand_params['conv2.weight'][0][1], final_rand_params['conv2.weight'][1][0], final_rand_params['conv2.weight'][1][1], final_rand_params['conv2.weight'][2][0], final_rand_params['conv2.weight'][2][1], final_rand_params['conv2.weight'][3][0], final_rand_params['conv2.weight'][3][1]]\n","\n","\n","for i in range(10):\n","    print(initial_filters[i].shape)\n","    filter1 = initial_filters[i].reshape(3,3)\n","    print(filter1.shape)\n","    filter2 = final_filters[i].reshape(3,3)\n","    similarity = calc_pearson_coeff(filter1, filter2)\n","    sims.append(similarity)\n","\n","print(sims)\n","\n","\n","for i in range(10):\n","    \n","    filter1 = initial_rand_filters[i].reshape(3,3)\n","    \n","    filter2 = final_rand_filters[i].reshape(3,3)\n","    similarity = calc_pearson_coeff(filter1, filter2)\n","    sims_rand.append(similarity)\n","\n","print(sims_rand)\n","\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
